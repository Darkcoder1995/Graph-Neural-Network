{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darkcoder1995/Graph-Neural-Network/blob/main/Graph_Transformer_ETA_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGRp8mCLxvoE",
        "outputId": "71983d46-6c70-4803-f2a7-2f63a3f34998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO_PNyDg3Ipn",
        "outputId": "8c5d20bb-2d52-4933-f6a3-05a95fc06e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n",
            "Installing collected packages: torch_scatter, torch_sparse\n",
            "Successfully installed torch_scatter-2.1.2+pt26cu124 torch_sparse-0.6.18+pt26cu124\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9nbOvj33N7n",
        "outputId": "e2393bff-93ca-4273-d54f-a67ba42a4842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sodapy\n",
            "  Downloading sodapy-2.2.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from sodapy) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (2025.4.26)\n",
            "Downloading sodapy-2.2.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: sodapy\n",
            "Successfully installed sodapy-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sodapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8Sx-N3Y3RVY",
        "outputId": "c4c3d115-47a6-49fd-fb47-841302c271ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openrouteservice\n",
            "  Downloading openrouteservice-2.3.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.11/dist-packages (from openrouteservice) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (2025.4.26)\n",
            "Downloading openrouteservice-2.3.3-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: openrouteservice\n",
            "Successfully installed openrouteservice-2.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openrouteservice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMow5gnt3Uds"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, GATConv\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from sodapy import Socrata\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "from sklearn.neighbors import BallTree\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "\n",
        "import openrouteservice\n",
        "from tqdm import tqdm\n",
        "from openrouteservice import Client\n",
        "from openrouteservice.exceptions import ApiError\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import softmax\n",
        "import torch.optim as optim\n",
        "from torch_scatter import scatter\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.decomposition import PCA\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1INicB_3Zjq",
        "outputId": "3e7bb882-d4a9-4c05-ff80-f898b80ffa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download Green Taxi Trip Data (Sept 2015)\n",
        "client = Socrata(\"data.cityofnewyork.us\", None)\n",
        "results = client.get(\"gi8d-wdg5\", limit=10000)\n",
        "results_df = pd.DataFrame.from_records(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1cTxiyv4cus"
      },
      "outputs": [],
      "source": [
        "min_pickup_datetime = results_df['lpep_pickup_datetime'].min()\n",
        "max_dropoff_datetime = results_df['lpep_dropoff_datetime'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSUXv5f84f9S",
        "outputId": "5c0d7ed8-e5d1-4219-cbd5-8b42b57b02e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    station_id  latitude  longitude  elevation state                   name  \\\n",
            "0  ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
            "1  ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
            "2  AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
            "3  AEM00041194   25.2550    55.3640       10.4   NaN             DUBAI INTL   \n",
            "4  AEM00041217   24.4330    54.6510       26.8   NaN         ABU DHABI INTL   \n",
            "\n",
            "  gsn_flag hcn_crn_flag   wmo_id  \n",
            "0      NaN          NaN      NaN  \n",
            "1      NaN          NaN      NaN  \n",
            "2      GSN          NaN  41196.0  \n",
            "3      NaN          NaN  41194.0  \n",
            "4      NaN          NaN  41217.0  \n"
          ]
        }
      ],
      "source": [
        "# URL of the station file\n",
        "url = \"https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\"\n",
        "\n",
        "# Define fixed-width column specs (0-based indexing, end is exclusive)\n",
        "colspecs = [\n",
        "    (0, 11),   # ID\n",
        "    (12, 20),  # LATITUDE\n",
        "    (21, 30),  # LONGITUDE\n",
        "    (31, 37),  # ELEVATION\n",
        "    (38, 40),  # STATE\n",
        "    (41, 71),  # NAME\n",
        "    (72, 75),  # GSN FLAG\n",
        "    (76, 79),  # HCN/CRN FLAG\n",
        "    (80, 85),  # WMO ID\n",
        "]\n",
        "\n",
        "# Define column names\n",
        "column_names = [\n",
        "    \"station_id\", \"latitude\", \"longitude\", \"elevation\", \"state\",\n",
        "    \"name\", \"gsn_flag\", \"hcn_crn_flag\", \"wmo_id\"\n",
        "]\n",
        "\n",
        "# Read the file using read_fwf (fixed-width format)\n",
        "stations_df = pd.read_fwf(url, colspecs=colspecs, names=column_names)\n",
        "\n",
        "# Display a few rows\n",
        "print(stations_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t1QprPp4ivl"
      },
      "outputs": [],
      "source": [
        "# Ensure all coordinate columns are numeric\n",
        "stations_df['latitude'] = pd.to_numeric(stations_df['latitude'], errors='coerce')\n",
        "stations_df['longitude'] = pd.to_numeric(stations_df['longitude'], errors='coerce')\n",
        "\n",
        "results_df['pickup_latitude'] = pd.to_numeric(results_df['pickup_latitude'], errors='coerce')\n",
        "results_df['pickup_longitude'] = pd.to_numeric(results_df['pickup_longitude'], errors='coerce')\n",
        "results_df['dropoff_latitude'] = pd.to_numeric(results_df['dropoff_latitude'], errors='coerce')\n",
        "results_df['dropoff_longitude'] = pd.to_numeric(results_df['dropoff_longitude'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV8gSi4n4oIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ad1d7c55-3bdb-4fff-8040-ed7d49052750"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-62a509d7c11c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Find nearest station index for each pickup and dropoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpickup_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickup_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickup_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdropoff_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropoff_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropoff_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Map nearest station details back to results_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Convert to radians for Haversine distance\n",
        "weather_coords = np.radians(stations_df[['latitude', 'longitude']].values)\n",
        "pickup_coords = np.radians(results_df[['pickup_latitude', 'pickup_longitude']].values)\n",
        "dropoff_coords = np.radians(results_df[['dropoff_latitude', 'dropoff_longitude']].values)\n",
        "\n",
        "# Build BallTree using weather station coordinates\n",
        "tree = BallTree(weather_coords, metric='haversine')\n",
        "\n",
        "# Find nearest station index for each pickup and dropoff\n",
        "pickup_dist, pickup_idx = tree.query(pickup_coords, k=1)\n",
        "dropoff_dist, dropoff_idx = tree.query(dropoff_coords, k=1)\n",
        "\n",
        "# Map nearest station details back to results_df\n",
        "results_df['pickup_station_id'] = stations_df.iloc[pickup_idx.flatten()]['station_id'].values\n",
        "results_df['pickup_station_lat'] = stations_df.iloc[pickup_idx.flatten()]['latitude'].values\n",
        "results_df['pickup_station_lon'] = stations_df.iloc[pickup_idx.flatten()]['longitude'].values\n",
        "\n",
        "results_df['dropoff_station_id'] = stations_df.iloc[dropoff_idx.flatten()]['station_id'].values\n",
        "results_df['dropoff_station_lat'] = stations_df.iloc[dropoff_idx.flatten()]['latitude'].values\n",
        "results_df['dropoff_station_lon'] = stations_df.iloc[dropoff_idx.flatten()]['longitude'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJiFYU584tFd"
      },
      "outputs": [],
      "source": [
        "# NOAA API setup\n",
        "TOKEN = \"MFymOYvQmUjLkLmwBZxzzzRxrcWnGVqj\"\n",
        "headers = {'token': TOKEN}\n",
        "base_url = \"https://www.ncei.noaa.gov/cdo-web/api/v2/data\"\n",
        "\n",
        "# Prepare unique station IDs from both pickup and dropoff\n",
        "unique_stations = pd.unique(\n",
        "    pd.concat([\n",
        "        results_df['pickup_station_id'],\n",
        "        results_df['dropoff_station_id']\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Ensure dates are in YYYY-MM-DD format strings\n",
        "start_date = pd.to_datetime(results_df['lpep_pickup_datetime'].min()).strftime(\"%Y-%m-%d\")\n",
        "end_date = pd.to_datetime(results_df['lpep_dropoff_datetime'].max()).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Dictionary to hold weather data for each station-date\n",
        "weather_dict = {}\n",
        "\n",
        "for station_id in unique_stations:\n",
        "    full_station_id = f\"GHCND:{station_id}\"\n",
        "\n",
        "    # Set API parameters\n",
        "    params = {\n",
        "        'datasetid': 'GHCND',\n",
        "        'stationid': full_station_id,\n",
        "        'startdate': start_date,\n",
        "        'enddate': end_date,\n",
        "        'limit': 1000,       # NOAA limits responses; consider pagination\n",
        "        'units': 'metric'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, headers=headers, params=params)\n",
        "        response.raise_for_status()  # Raise error for bad responses\n",
        "        data = response.json()\n",
        "\n",
        "        # Parse response data\n",
        "        for item in data.get('results', []):\n",
        "            date = item['date'][:10]\n",
        "            key = (station_id, date)  # Tuple key: (station_id, date)\n",
        "            if key not in weather_dict:\n",
        "                weather_dict[key] = {}\n",
        "            weather_dict[key][item['datatype']] = item['value']\n",
        "\n",
        "        time.sleep(1)  # Be polite to NOAA API (1-second delay)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for station {station_id}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7d-adTx4wc6"
      },
      "outputs": [],
      "source": [
        "weather_df = pd.DataFrame([\n",
        "    {'station_id': sid, 'date': date, **metrics}\n",
        "    for (sid, date), metrics in weather_dict.items()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l81XvEA45mu"
      },
      "outputs": [],
      "source": [
        "for column in weather_df.columns:\n",
        "    if weather_df[column].isnull().any():\n",
        "        median_value = weather_df[column].median()\n",
        "        weather_df[column] = weather_df[column].fillna(median_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpQrBUC848YR"
      },
      "outputs": [],
      "source": [
        "# 1. Ensure date format\n",
        "results_df['pickup_date'] = pd.to_datetime(results_df['lpep_pickup_datetime']).dt.date\n",
        "results_df['dropoff_date'] = pd.to_datetime(results_df['lpep_dropoff_datetime']).dt.date\n",
        "weather_df['date'] = pd.to_datetime(weather_df['date']).dt.date\n",
        "\n",
        "# 2. Rename weather columns BEFORE merging (avoid suffix conflicts)\n",
        "pickup_weather_df = weather_df.rename(columns=lambda col: f\"pickup_{col}\" if col not in ['station_id', 'date'] else col)\n",
        "dropoff_weather_df = weather_df.rename(columns=lambda col: f\"dropoff_{col}\" if col not in ['station_id', 'date'] else col)\n",
        "\n",
        "# 3. Merge pickup weather (INNER)\n",
        "pickup_matched = results_df.merge(\n",
        "    pickup_weather_df,\n",
        "    left_on=['pickup_station_id', 'pickup_date'],\n",
        "    right_on=['station_id', 'date'],\n",
        "    how='inner'\n",
        ").drop(columns=['station_id', 'date'])\n",
        "\n",
        "# 4. Pickup unmatched\n",
        "pickup_unmatched = results_df.merge(\n",
        "    pickup_weather_df[['station_id', 'date']],\n",
        "    left_on=['pickup_station_id', 'pickup_date'],\n",
        "    right_on=['station_id', 'date'],\n",
        "    how='left',\n",
        "    indicator=True\n",
        ").query(\"_merge == 'left_only'\").drop(columns=['station_id', 'date', '_merge'])\n",
        "\n",
        "# Add missing pickup weather as 0\n",
        "for col in pickup_weather_df.columns:\n",
        "    if col not in ['station_id', 'date']:\n",
        "        pickup_unmatched[col] = 0\n",
        "\n",
        "# 5. Combine both pickup matched and unmatched\n",
        "results_df_pickup = pd.concat([pickup_matched, pickup_unmatched], ignore_index=True)\n",
        "\n",
        "# 6. Merge dropoff weather (INNER)\n",
        "dropoff_matched = results_df_pickup.merge(\n",
        "    dropoff_weather_df,\n",
        "    left_on=['dropoff_station_id', 'dropoff_date'],\n",
        "    right_on=['station_id', 'date'],\n",
        "    how='inner'\n",
        ").drop(columns=['station_id', 'date'])\n",
        "\n",
        "# 7. Dropoff unmatched\n",
        "dropoff_unmatched = results_df_pickup.merge(\n",
        "    dropoff_weather_df[['station_id', 'date']],\n",
        "    left_on=['dropoff_station_id', 'dropoff_date'],\n",
        "    right_on=['station_id', 'date'],\n",
        "    how='left',\n",
        "    indicator=True\n",
        ").query(\"_merge == 'left_only'\").drop(columns=['station_id', 'date', '_merge'])\n",
        "\n",
        "# Add missing dropoff weather as 0\n",
        "for col in dropoff_weather_df.columns:\n",
        "    if col not in ['station_id', 'date']:\n",
        "        dropoff_unmatched[col] = 0\n",
        "\n",
        "# 8. Combine matched + unmatched to form final dataset\n",
        "results_df_final = pd.concat([dropoff_matched, dropoff_unmatched], ignore_index=True)\n",
        "\n",
        "# 9. Final cleanup (in case 'station_id' and 'date' columns are present)\n",
        "results_df_final.drop(columns=['station_id', 'date'], inplace=True, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEjTwkx94_KO",
        "outputId": "1151a15e-5246-4c52-9646-6220917e4639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No columns with NaN values.\n"
          ]
        }
      ],
      "source": [
        "# Check for NaN values in each column of results_df\n",
        "nan_counts = results_df_final.isnull().sum()\n",
        "\n",
        "# Print the count of NaN values for each column\n",
        "if nan_counts.any():\n",
        "    print(\"Columns with NaN values:\")\n",
        "    print(nan_counts)\n",
        "else:\n",
        "    print(\"No columns with NaN values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh6UttzY5Gr9"
      },
      "outputs": [],
      "source": [
        "api_key = '5b3ce3597851110001cf6248e5517d57f84a48f79ade0b581ebe78cf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz36uZrw_Hxg",
        "outputId": "2735df67-669d-477f-9996-09380bfbf7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [06:28<00:00,  1.94s/it]\n"
          ]
        }
      ],
      "source": [
        "# USE THIS-----\n",
        "# ORS client already initialized\n",
        "client = openrouteservice.Client(key=api_key)\n",
        "\n",
        "# Create list of coordinate pairs\n",
        "coordinates = list(zip(\n",
        "    results_df_final['pickup_longitude'],\n",
        "    results_df_final['pickup_latitude'],\n",
        "    results_df_final['dropoff_longitude'],\n",
        "    results_df_final['dropoff_latitude']\n",
        "))\n",
        "\n",
        "# ORS supports up to 50 locations in matrix request; do batches\n",
        "batch_size = 50\n",
        "durations = []\n",
        "distances = []\n",
        "\n",
        "for i in tqdm(range(0, len(coordinates), batch_size)):\n",
        "    batch = coordinates[i:i+batch_size]\n",
        "\n",
        "    # Prepare source and destination coordinates\n",
        "    locations = [[lon1, lat1] for lon1, lat1, lon2, lat2 in batch]\n",
        "    destinations = [[lon2, lat2] for lon1, lat1, lon2, lat2 in batch]\n",
        "\n",
        "    try:\n",
        "        matrix = client.distance_matrix(\n",
        "            locations=locations + destinations,\n",
        "            sources=list(range(len(locations))),\n",
        "            destinations=list(range(len(locations), len(locations) + len(destinations))),\n",
        "            metrics=[\"distance\", \"duration\"],\n",
        "            resolve_locations=True,\n",
        "            units='m'\n",
        "        )\n",
        "\n",
        "        # Each result is row i's pickup to row i's dropoff\n",
        "        durations.extend([row[i] for i, row in enumerate(matrix['durations'])])\n",
        "        distances.extend([row[i] for i, row in enumerate(matrix['distances'])])\n",
        "\n",
        "    except ApiError as e:\n",
        "        print(f\"API Error on batch {i}: {e}\")\n",
        "        durations.extend([None]*len(batch))\n",
        "        distances.extend([None]*len(batch))\n",
        "        time.sleep(5)\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"General error on batch {i}: {e}\")\n",
        "        durations.extend([None]*len(batch))\n",
        "        distances.extend([None]*len(batch))\n",
        "        time.sleep(5)\n",
        "        continue\n",
        "\n",
        "    # Be polite to the API\n",
        "    time.sleep(1)\n",
        "\n",
        "# Add back to DataFrame\n",
        "results_df_final['ors_distance_m'] = distances\n",
        "results_df_final['ors_duration_s'] = durations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T122fA6_vGG"
      },
      "outputs": [],
      "source": [
        "# # # prompt: where will it be saved\n",
        "\n",
        "# results_df_final.to_csv('processed_taxi_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5rpThu96QY8"
      },
      "outputs": [],
      "source": [
        "# # # # prompt: read results_df_final csv file\n",
        "# #\n",
        "results_df_final = pd.read_csv('processed_taxi_data (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "4oLqD89L6cMT",
        "outputId": "7c9e40ea-a60a-4046-bd16-b475835a7cdd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      vendorid     lpep_pickup_datetime    lpep_dropoff_datetime  \\\n",
              "0            1  2015-02-13T19:49:20.000  2015-02-13T19:53:49.000   \n",
              "1            2  2015-02-26T19:17:29.000  2015-02-26T19:22:41.000   \n",
              "2            2  2015-02-17T14:10:19.000  2015-02-17T14:20:44.000   \n",
              "3            2  2015-02-06T21:07:34.000  2015-02-06T21:13:26.000   \n",
              "4            1  2015-02-19T08:41:04.000  2015-02-19T08:49:17.000   \n",
              "...        ...                      ...                      ...   \n",
              "9995         1  2015-02-14T10:21:02.000  2015-02-14T10:27:27.000   \n",
              "9996         2  2015-02-12T22:02:31.000  2015-02-12T22:11:26.000   \n",
              "9997         1  2015-02-26T22:04:06.000  2015-02-26T22:12:26.000   \n",
              "9998         2  2015-02-25T21:32:05.000  2015-02-25T22:07:30.000   \n",
              "9999         2  2015-02-14T01:33:13.000  2015-02-14T01:45:17.000   \n",
              "\n",
              "     store_and_fwd_flag  ratecodeid  pickup_longitude  pickup_latitude  \\\n",
              "0                     N           1        -73.994896        40.684578   \n",
              "1                     N           1        -73.993149        40.692768   \n",
              "2                     N           1        -73.991631        40.685059   \n",
              "3                     N           1        -73.910004        40.775623   \n",
              "4                     N           1        -74.000633        40.682995   \n",
              "...                 ...         ...               ...              ...   \n",
              "9995                  N           1        -73.942337        40.754093   \n",
              "9996                  N           1        -73.886497        40.747299   \n",
              "9997                  N           1        -73.888702        40.747257   \n",
              "9998                  N           1        -73.933228        40.704975   \n",
              "9999                  N           1        -73.966133        40.683266   \n",
              "\n",
              "      dropoff_longitude  dropoff_latitude  passenger_count  trip_distance  \\\n",
              "0            -74.003479         40.680717                2           0.70   \n",
              "1            -74.002129         40.684917                1           0.93   \n",
              "2            -73.996834         40.680424                1           0.98   \n",
              "3            -73.890762         40.768871                1           1.32   \n",
              "4            -73.989708         40.702469                1           1.90   \n",
              "...                 ...               ...              ...            ...   \n",
              "9995         -73.924614         40.756371                1           1.30   \n",
              "9996         -73.865860         40.736572                1           1.54   \n",
              "9997         -73.866844         40.750011                1           1.40   \n",
              "9998         -73.980232         40.672199                6           5.54   \n",
              "9999         -73.925911         40.691242                6           2.77   \n",
              "\n",
              "      fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
              "0             5.0    1.0      0.5        0.00           0.0   \n",
              "1             5.0    1.0      0.5        1.36           0.0   \n",
              "2             8.0    0.0      0.5        0.00           0.0   \n",
              "3             6.5    0.5      0.5        0.00           0.0   \n",
              "4             8.5    0.0      0.5        1.85           0.0   \n",
              "...           ...    ...      ...         ...           ...   \n",
              "9995          6.5    0.0      0.5        1.45           0.0   \n",
              "9996          8.0    0.5      0.5        3.00           0.0   \n",
              "9997          7.5    0.5      0.5        0.00           0.0   \n",
              "9998         26.0    0.5      0.5        0.00           0.0   \n",
              "9999         11.5    0.5      0.5        0.00           0.0   \n",
              "\n",
              "      improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
              "0                       0.3          6.80             2          1   \n",
              "1                       0.3          8.16             1          1   \n",
              "2                       0.3          8.80             2          1   \n",
              "3                       0.3          7.80             2          1   \n",
              "4                       0.3         11.15             1          1   \n",
              "...                     ...           ...           ...        ...   \n",
              "9995                    0.3          8.75             1          1   \n",
              "9996                    0.3         12.30             1          1   \n",
              "9997                    0.3          8.80             2          1   \n",
              "9998                    0.3         27.30             2          1   \n",
              "9999                    0.3         12.80             2          1   \n",
              "\n",
              "     pickup_station_id  pickup_station_lat  pickup_station_lon  \\\n",
              "0          US1NYKN0025             40.6846            -73.9867   \n",
              "1          US1NYKN0025             40.6846            -73.9867   \n",
              "2          US1NYKN0025             40.6846            -73.9867   \n",
              "3          USW00014732             40.7794            -73.8803   \n",
              "4          US1NYKN0025             40.6846            -73.9867   \n",
              "...                ...                 ...                 ...   \n",
              "9995       USC00305804             40.7333            -73.9333   \n",
              "9996       US1NYQN0026             40.7544            -73.8882   \n",
              "9997       US1NYQN0026             40.7544            -73.8882   \n",
              "9998       USC00300958             40.6892            -73.9550   \n",
              "9999       USC00300958             40.6892            -73.9550   \n",
              "\n",
              "     dropoff_station_id  dropoff_station_lat  dropoff_station_lon pickup_date  \\\n",
              "0           US1NYKN0025              40.6846             -73.9867  2015-02-13   \n",
              "1           US1NYKN0025              40.6846             -73.9867  2015-02-26   \n",
              "2           US1NYKN0025              40.6846             -73.9867  2015-02-17   \n",
              "3           USW00014732              40.7794             -73.8803  2015-02-06   \n",
              "4           US1NYKN0025              40.6846             -73.9867  2015-02-19   \n",
              "...                 ...                  ...                  ...         ...   \n",
              "9995        USC00305804              40.7333             -73.9333  2015-02-14   \n",
              "9996        US1NYQN0026              40.7544             -73.8882  2015-02-12   \n",
              "9997        USC00302868              40.7667             -73.8667  2015-02-26   \n",
              "9998        US1NYKN0059              40.6597             -73.9828  2015-02-25   \n",
              "9999        USC00300958              40.6892             -73.9550  2015-02-14   \n",
              "\n",
              "     dropoff_date  pickup_PRCP  pickup_SNOW  pickup_SNWD  pickup_WESF  \\\n",
              "0      2015-02-13          0.3          0.0         80.0          0.0   \n",
              "1      2015-02-26          0.0          0.0        127.0          0.0   \n",
              "2      2015-02-17          3.0         76.0        229.0          3.0   \n",
              "3      2015-02-06          0.0          0.0        150.0          0.0   \n",
              "4      2015-02-19          0.0          0.0        203.0          0.0   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995   2015-02-14          0.0          0.0          0.0          0.0   \n",
              "9996   2015-02-12          0.0          0.0          0.0          0.0   \n",
              "9997   2015-02-26          0.0          0.0          0.0          0.0   \n",
              "9998   2015-02-25          0.0          0.0          0.0          0.0   \n",
              "9999   2015-02-14          0.0          0.0          0.0          0.0   \n",
              "\n",
              "      pickup_WESD  pickup_DAPR  pickup_MDPR  pickup_ADPT  pickup_ASLP  \\\n",
              "0             0.0          5.0        17.65        -89.0      10207.0   \n",
              "1             0.0          5.0        17.65        -89.0      10207.0   \n",
              "2             0.0          5.0        17.65        -89.0      10207.0   \n",
              "3             0.0          5.0        17.65        -89.0      10207.0   \n",
              "4             0.0          5.0        17.65        -89.0      10207.0   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995          0.0          0.0         0.00          0.0          0.0   \n",
              "9996          0.0          0.0         0.00          0.0          0.0   \n",
              "9997          0.0          0.0         0.00          0.0          0.0   \n",
              "9998          0.0          0.0         0.00          0.0          0.0   \n",
              "9999          0.0          0.0         0.00          0.0          0.0   \n",
              "\n",
              "      pickup_ASTP  pickup_AWBT  pickup_AWND  pickup_RHAV  pickup_RHMN  \\\n",
              "0         10179.0        -39.0          4.4         55.5         38.0   \n",
              "1         10179.0        -39.0          4.4         55.5         38.0   \n",
              "2         10179.0        -39.0          4.4         55.5         38.0   \n",
              "3         10179.0        -39.0          5.5         55.5         38.0   \n",
              "4         10179.0        -39.0          4.4         55.5         38.0   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995          0.0          0.0          0.0          0.0          0.0   \n",
              "9996          0.0          0.0          0.0          0.0          0.0   \n",
              "9997          0.0          0.0          0.0          0.0          0.0   \n",
              "9998          0.0          0.0          0.0          0.0          0.0   \n",
              "9999          0.0          0.0          0.0          0.0          0.0   \n",
              "\n",
              "      pickup_RHMX  pickup_TMAX  pickup_TMIN  pickup_WDF2  pickup_WDF5  \\\n",
              "0            76.0          2.8         -6.0        280.0        290.0   \n",
              "1            76.0          2.8         -6.0        280.0        290.0   \n",
              "2            76.0          2.8         -6.0        280.0        290.0   \n",
              "3            76.0         -2.7        -11.0        260.0        260.0   \n",
              "4            76.0          2.8         -6.0        280.0        290.0   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995          0.0          0.0          0.0          0.0          0.0   \n",
              "9996          0.0          0.0          0.0          0.0          0.0   \n",
              "9997          0.0          0.0          0.0          0.0          0.0   \n",
              "9998          0.0          0.0          0.0          0.0          0.0   \n",
              "9999          0.0          0.0          0.0          0.0          0.0   \n",
              "\n",
              "      pickup_WSF2  pickup_WSF5  pickup_WT01  pickup_WT08  pickup_WT04  \\\n",
              "0             9.4         12.5          1.0          1.0          1.0   \n",
              "1             9.4         12.5          1.0          1.0          1.0   \n",
              "2             9.4         12.5          1.0          1.0          1.0   \n",
              "3            10.3         13.9          1.0          1.0          1.0   \n",
              "4             9.4         12.5          1.0          1.0          1.0   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995          0.0          0.0          0.0          0.0          0.0   \n",
              "9996          0.0          0.0          0.0          0.0          0.0   \n",
              "9997          0.0          0.0          0.0          0.0          0.0   \n",
              "9998          0.0          0.0          0.0          0.0          0.0   \n",
              "9999          0.0          0.0          0.0          0.0          0.0   \n",
              "\n",
              "      pickup_WT02  pickup_WT06  pickup_TAVG  pickup_WT09  pickup_WT03  \\\n",
              "0             1.0          1.0          0.4          1.0          1.0   \n",
              "1             1.0          1.0          0.4          1.0          1.0   \n",
              "2             1.0          1.0          0.4          1.0          1.0   \n",
              "3             1.0          1.0         -7.7          1.0          1.0   \n",
              "4             1.0          1.0          0.4          1.0          1.0   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995          0.0          0.0          0.0          0.0          0.0   \n",
              "9996          0.0          0.0          0.0          0.0          0.0   \n",
              "9997          0.0          0.0          0.0          0.0          0.0   \n",
              "9998          0.0          0.0          0.0          0.0          0.0   \n",
              "9999          0.0          0.0          0.0          0.0          0.0   \n",
              "\n",
              "      dropoff_PRCP  dropoff_SNOW  dropoff_SNWD  dropoff_WESF  dropoff_WESD  \\\n",
              "0              0.3           0.0          80.0           0.0           0.0   \n",
              "1              0.0           0.0         127.0           0.0           0.0   \n",
              "2              3.0          76.0         229.0           3.0           0.0   \n",
              "3              0.0           0.0         150.0           0.0           0.0   \n",
              "4              0.0           0.0         203.0           0.0           0.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995           0.0           0.0           0.0           0.0           0.0   \n",
              "9996           0.0           0.0           0.0           0.0           0.0   \n",
              "9997           0.0           0.0           0.0           0.0           0.0   \n",
              "9998           0.0           0.0           0.0           0.0           0.0   \n",
              "9999           0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      dropoff_DAPR  dropoff_MDPR  dropoff_ADPT  dropoff_ASLP  dropoff_ASTP  \\\n",
              "0              5.0         17.65         -89.0       10207.0       10179.0   \n",
              "1              5.0         17.65         -89.0       10207.0       10179.0   \n",
              "2              5.0         17.65         -89.0       10207.0       10179.0   \n",
              "3              5.0         17.65         -89.0       10207.0       10179.0   \n",
              "4              5.0         17.65         -89.0       10207.0       10179.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995           0.0          0.00           0.0           0.0           0.0   \n",
              "9996           0.0          0.00           0.0           0.0           0.0   \n",
              "9997           0.0          0.00           0.0           0.0           0.0   \n",
              "9998           0.0          0.00           0.0           0.0           0.0   \n",
              "9999           0.0          0.00           0.0           0.0           0.0   \n",
              "\n",
              "      dropoff_AWBT  dropoff_AWND  dropoff_RHAV  dropoff_RHMN  dropoff_RHMX  \\\n",
              "0            -39.0           4.4          55.5          38.0          76.0   \n",
              "1            -39.0           4.4          55.5          38.0          76.0   \n",
              "2            -39.0           4.4          55.5          38.0          76.0   \n",
              "3            -39.0           5.5          55.5          38.0          76.0   \n",
              "4            -39.0           4.4          55.5          38.0          76.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995           0.0           0.0           0.0           0.0           0.0   \n",
              "9996           0.0           0.0           0.0           0.0           0.0   \n",
              "9997           0.0           0.0           0.0           0.0           0.0   \n",
              "9998           0.0           0.0           0.0           0.0           0.0   \n",
              "9999           0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      dropoff_TMAX  dropoff_TMIN  dropoff_WDF2  dropoff_WDF5  dropoff_WSF2  \\\n",
              "0              2.8          -6.0         280.0         290.0           9.4   \n",
              "1              2.8          -6.0         280.0         290.0           9.4   \n",
              "2              2.8          -6.0         280.0         290.0           9.4   \n",
              "3             -2.7         -11.0         260.0         260.0          10.3   \n",
              "4              2.8          -6.0         280.0         290.0           9.4   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995           0.0           0.0           0.0           0.0           0.0   \n",
              "9996           0.0           0.0           0.0           0.0           0.0   \n",
              "9997           0.0           0.0           0.0           0.0           0.0   \n",
              "9998           0.0           0.0           0.0           0.0           0.0   \n",
              "9999           0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      dropoff_WSF5  dropoff_WT01  dropoff_WT08  dropoff_WT04  dropoff_WT02  \\\n",
              "0             12.5           1.0           1.0           1.0           1.0   \n",
              "1             12.5           1.0           1.0           1.0           1.0   \n",
              "2             12.5           1.0           1.0           1.0           1.0   \n",
              "3             13.9           1.0           1.0           1.0           1.0   \n",
              "4             12.5           1.0           1.0           1.0           1.0   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995           0.0           0.0           0.0           0.0           0.0   \n",
              "9996           0.0           0.0           0.0           0.0           0.0   \n",
              "9997           0.0           0.0           0.0           0.0           0.0   \n",
              "9998           0.0           0.0           0.0           0.0           0.0   \n",
              "9999           0.0           0.0           0.0           0.0           0.0   \n",
              "\n",
              "      dropoff_WT06  dropoff_TAVG  dropoff_WT09  dropoff_WT03  ors_distance_m  \\\n",
              "0              1.0           0.4           1.0           1.0         1189.78   \n",
              "1              1.0           0.4           1.0           1.0         1729.93   \n",
              "2              1.0           0.4           1.0           1.0         1009.86   \n",
              "3              1.0          -7.7           1.0           1.0         2146.68   \n",
              "4              1.0           0.4           1.0           1.0         3206.94   \n",
              "...            ...           ...           ...           ...             ...   \n",
              "9995           0.0           0.0           0.0           0.0         2059.21   \n",
              "9996           0.0           0.0           0.0           0.0         2897.91   \n",
              "9997           0.0           0.0           0.0           0.0         2406.82   \n",
              "9998           0.0           0.0           0.0           0.0         7573.46   \n",
              "9999           0.0           0.0           0.0           0.0         5098.69   \n",
              "\n",
              "      ors_duration_s  \n",
              "0             190.70  \n",
              "1             298.64  \n",
              "2             104.94  \n",
              "3             211.62  \n",
              "4             401.07  \n",
              "...              ...  \n",
              "9995          233.33  \n",
              "9996          232.28  \n",
              "9997          298.07  \n",
              "9998          884.20  \n",
              "9999          555.39  \n",
              "\n",
              "[10000 rows x 88 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8377379-fd74-4c87-a7ea-fef9093f9d28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vendorid</th>\n",
              "      <th>lpep_pickup_datetime</th>\n",
              "      <th>lpep_dropoff_datetime</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>ratecodeid</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>trip_type</th>\n",
              "      <th>pickup_station_id</th>\n",
              "      <th>pickup_station_lat</th>\n",
              "      <th>pickup_station_lon</th>\n",
              "      <th>dropoff_station_id</th>\n",
              "      <th>dropoff_station_lat</th>\n",
              "      <th>dropoff_station_lon</th>\n",
              "      <th>pickup_date</th>\n",
              "      <th>dropoff_date</th>\n",
              "      <th>pickup_PRCP</th>\n",
              "      <th>pickup_SNOW</th>\n",
              "      <th>pickup_SNWD</th>\n",
              "      <th>pickup_WESF</th>\n",
              "      <th>pickup_WESD</th>\n",
              "      <th>pickup_DAPR</th>\n",
              "      <th>pickup_MDPR</th>\n",
              "      <th>pickup_ADPT</th>\n",
              "      <th>pickup_ASLP</th>\n",
              "      <th>pickup_ASTP</th>\n",
              "      <th>pickup_AWBT</th>\n",
              "      <th>pickup_AWND</th>\n",
              "      <th>pickup_RHAV</th>\n",
              "      <th>pickup_RHMN</th>\n",
              "      <th>pickup_RHMX</th>\n",
              "      <th>pickup_TMAX</th>\n",
              "      <th>pickup_TMIN</th>\n",
              "      <th>pickup_WDF2</th>\n",
              "      <th>pickup_WDF5</th>\n",
              "      <th>pickup_WSF2</th>\n",
              "      <th>pickup_WSF5</th>\n",
              "      <th>pickup_WT01</th>\n",
              "      <th>pickup_WT08</th>\n",
              "      <th>pickup_WT04</th>\n",
              "      <th>pickup_WT02</th>\n",
              "      <th>pickup_WT06</th>\n",
              "      <th>pickup_TAVG</th>\n",
              "      <th>pickup_WT09</th>\n",
              "      <th>pickup_WT03</th>\n",
              "      <th>dropoff_PRCP</th>\n",
              "      <th>dropoff_SNOW</th>\n",
              "      <th>dropoff_SNWD</th>\n",
              "      <th>dropoff_WESF</th>\n",
              "      <th>dropoff_WESD</th>\n",
              "      <th>dropoff_DAPR</th>\n",
              "      <th>dropoff_MDPR</th>\n",
              "      <th>dropoff_ADPT</th>\n",
              "      <th>dropoff_ASLP</th>\n",
              "      <th>dropoff_ASTP</th>\n",
              "      <th>dropoff_AWBT</th>\n",
              "      <th>dropoff_AWND</th>\n",
              "      <th>dropoff_RHAV</th>\n",
              "      <th>dropoff_RHMN</th>\n",
              "      <th>dropoff_RHMX</th>\n",
              "      <th>dropoff_TMAX</th>\n",
              "      <th>dropoff_TMIN</th>\n",
              "      <th>dropoff_WDF2</th>\n",
              "      <th>dropoff_WDF5</th>\n",
              "      <th>dropoff_WSF2</th>\n",
              "      <th>dropoff_WSF5</th>\n",
              "      <th>dropoff_WT01</th>\n",
              "      <th>dropoff_WT08</th>\n",
              "      <th>dropoff_WT04</th>\n",
              "      <th>dropoff_WT02</th>\n",
              "      <th>dropoff_WT06</th>\n",
              "      <th>dropoff_TAVG</th>\n",
              "      <th>dropoff_WT09</th>\n",
              "      <th>dropoff_WT03</th>\n",
              "      <th>ors_distance_m</th>\n",
              "      <th>ors_duration_s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-13T19:49:20.000</td>\n",
              "      <td>2015-02-13T19:53:49.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.994896</td>\n",
              "      <td>40.684578</td>\n",
              "      <td>-74.003479</td>\n",
              "      <td>40.680717</td>\n",
              "      <td>2</td>\n",
              "      <td>0.70</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>6.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-13</td>\n",
              "      <td>2015-02-13</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1189.78</td>\n",
              "      <td>190.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-26T19:17:29.000</td>\n",
              "      <td>2015-02-26T19:22:41.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.993149</td>\n",
              "      <td>40.692768</td>\n",
              "      <td>-74.002129</td>\n",
              "      <td>40.684917</td>\n",
              "      <td>1</td>\n",
              "      <td>0.93</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1729.93</td>\n",
              "      <td>298.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-17T14:10:19.000</td>\n",
              "      <td>2015-02-17T14:20:44.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.991631</td>\n",
              "      <td>40.685059</td>\n",
              "      <td>-73.996834</td>\n",
              "      <td>40.680424</td>\n",
              "      <td>1</td>\n",
              "      <td>0.98</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-17</td>\n",
              "      <td>2015-02-17</td>\n",
              "      <td>3.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1009.86</td>\n",
              "      <td>104.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-06T21:07:34.000</td>\n",
              "      <td>2015-02-06T21:13:26.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.910004</td>\n",
              "      <td>40.775623</td>\n",
              "      <td>-73.890762</td>\n",
              "      <td>40.768871</td>\n",
              "      <td>1</td>\n",
              "      <td>1.32</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>7.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>USW00014732</td>\n",
              "      <td>40.7794</td>\n",
              "      <td>-73.8803</td>\n",
              "      <td>USW00014732</td>\n",
              "      <td>40.7794</td>\n",
              "      <td>-73.8803</td>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>13.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>13.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-7.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2146.68</td>\n",
              "      <td>211.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-19T08:41:04.000</td>\n",
              "      <td>2015-02-19T08:49:17.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.000633</td>\n",
              "      <td>40.682995</td>\n",
              "      <td>-73.989708</td>\n",
              "      <td>40.702469</td>\n",
              "      <td>1</td>\n",
              "      <td>1.90</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>11.15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-19</td>\n",
              "      <td>2015-02-19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>17.65</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>10207.0</td>\n",
              "      <td>10179.0</td>\n",
              "      <td>-39.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>55.5</td>\n",
              "      <td>38.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>290.0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3206.94</td>\n",
              "      <td>401.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-14T10:21:02.000</td>\n",
              "      <td>2015-02-14T10:27:27.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.942337</td>\n",
              "      <td>40.754093</td>\n",
              "      <td>-73.924614</td>\n",
              "      <td>40.756371</td>\n",
              "      <td>1</td>\n",
              "      <td>1.30</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>USC00305804</td>\n",
              "      <td>40.7333</td>\n",
              "      <td>-73.9333</td>\n",
              "      <td>USC00305804</td>\n",
              "      <td>40.7333</td>\n",
              "      <td>-73.9333</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2059.21</td>\n",
              "      <td>233.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-12T22:02:31.000</td>\n",
              "      <td>2015-02-12T22:11:26.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.886497</td>\n",
              "      <td>40.747299</td>\n",
              "      <td>-73.865860</td>\n",
              "      <td>40.736572</td>\n",
              "      <td>1</td>\n",
              "      <td>1.54</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>12.30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYQN0026</td>\n",
              "      <td>40.7544</td>\n",
              "      <td>-73.8882</td>\n",
              "      <td>US1NYQN0026</td>\n",
              "      <td>40.7544</td>\n",
              "      <td>-73.8882</td>\n",
              "      <td>2015-02-12</td>\n",
              "      <td>2015-02-12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2897.91</td>\n",
              "      <td>232.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-26T22:04:06.000</td>\n",
              "      <td>2015-02-26T22:12:26.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.888702</td>\n",
              "      <td>40.747257</td>\n",
              "      <td>-73.866844</td>\n",
              "      <td>40.750011</td>\n",
              "      <td>1</td>\n",
              "      <td>1.40</td>\n",
              "      <td>7.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>8.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYQN0026</td>\n",
              "      <td>40.7544</td>\n",
              "      <td>-73.8882</td>\n",
              "      <td>USC00302868</td>\n",
              "      <td>40.7667</td>\n",
              "      <td>-73.8667</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2406.82</td>\n",
              "      <td>298.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-25T21:32:05.000</td>\n",
              "      <td>2015-02-25T22:07:30.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.933228</td>\n",
              "      <td>40.704975</td>\n",
              "      <td>-73.980232</td>\n",
              "      <td>40.672199</td>\n",
              "      <td>6</td>\n",
              "      <td>5.54</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>27.30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>USC00300958</td>\n",
              "      <td>40.6892</td>\n",
              "      <td>-73.9550</td>\n",
              "      <td>US1NYKN0059</td>\n",
              "      <td>40.6597</td>\n",
              "      <td>-73.9828</td>\n",
              "      <td>2015-02-25</td>\n",
              "      <td>2015-02-25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7573.46</td>\n",
              "      <td>884.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-14T01:33:13.000</td>\n",
              "      <td>2015-02-14T01:45:17.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.966133</td>\n",
              "      <td>40.683266</td>\n",
              "      <td>-73.925911</td>\n",
              "      <td>40.691242</td>\n",
              "      <td>6</td>\n",
              "      <td>2.77</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>12.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>USC00300958</td>\n",
              "      <td>40.6892</td>\n",
              "      <td>-73.9550</td>\n",
              "      <td>USC00300958</td>\n",
              "      <td>40.6892</td>\n",
              "      <td>-73.9550</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5098.69</td>\n",
              "      <td>555.39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 88 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8377379-fd74-4c87-a7ea-fef9093f9d28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8377379-fd74-4c87-a7ea-fef9093f9d28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8377379-fd74-4c87-a7ea-fef9093f9d28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04945bb0-87a8-437c-a34c-0426964014a1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04945bb0-87a8-437c-a34c-0426964014a1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04945bb0-87a8-437c-a34c-0426964014a1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1ed4ef85-c661-4103-9079-89db52fde0ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1ed4ef85-c661-4103-9079-89db52fde0ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_final"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "display(results_df_final)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: drop ors_duration_s from result_df\n",
        "\n",
        "results_df_final = results_df_final.drop(columns=['ors_duration_s'], errors='ignore')"
      ],
      "metadata": {
        "id": "HRFj68FVEQRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gBq1tc_676X"
      },
      "outputs": [],
      "source": [
        "# Define weather columns (pickup + dropoff)\n",
        "weather_columns = [\n",
        "    'pickup_PRCP', 'pickup_SNOW', 'pickup_SNWD', 'pickup_WESF', 'pickup_WESD', 'pickup_DAPR',\n",
        "    'pickup_MDPR', 'pickup_ADPT', 'pickup_ASLP', 'pickup_ASTP', 'pickup_AWBT', 'pickup_AWND',\n",
        "    'pickup_RHAV', 'pickup_RHMN', 'pickup_RHMX', 'pickup_TMAX', 'pickup_TMIN', 'pickup_WDF2',\n",
        "    'pickup_WDF5', 'pickup_WSF2', 'pickup_WSF5', 'pickup_WT01', 'pickup_WT08', 'pickup_WT04',\n",
        "    'pickup_WT02', 'pickup_WT06', 'pickup_TAVG', 'pickup_WT09', 'pickup_WT03',\n",
        "    'dropoff_PRCP', 'dropoff_SNOW', 'dropoff_SNWD', 'dropoff_WESF', 'dropoff_WESD', 'dropoff_DAPR',\n",
        "    'dropoff_MDPR', 'dropoff_ADPT', 'dropoff_ASLP', 'dropoff_ASTP', 'dropoff_AWBT', 'dropoff_AWND',\n",
        "    'dropoff_RHAV', 'dropoff_RHMN', 'dropoff_RHMX', 'dropoff_TMAX', 'dropoff_TMIN', 'dropoff_WDF2',\n",
        "    'dropoff_WDF5', 'dropoff_WSF2', 'dropoff_WSF5', 'dropoff_WT01', 'dropoff_WT08', 'dropoff_WT04',\n",
        "    'dropoff_WT02', 'dropoff_WT06', 'dropoff_TAVG', 'dropoff_WT09', 'dropoff_WT03'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfo3W_mZ7GyY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Combine trip-related and weather columns\n",
        "scale_columns = [\n",
        "    'trip_distance', 'passenger_count', 'fare_amount', 'tip_amount',\n",
        "    'total_amount', 'ors_distance_m'\n",
        "] + weather_columns  # Include weather data\n",
        "\n",
        "# Ensure numeric types (coerce non-numeric to NaN)\n",
        "results_df_final[scale_columns] = results_df_final[scale_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Remove or replace invalid (negative or NaN) values\n",
        "# Option 1: Fill NaNs with small value before log (safer for log1p)\n",
        "results_df_final[scale_columns] = results_df_final[scale_columns].fillna(0)\n",
        "\n",
        "# Optionally clip negatives if log1p is not safe for < -1\n",
        "results_df_final[scale_columns] = results_df_final[scale_columns].clip(lower=0)\n",
        "\n",
        "# Step 1: Apply log1p\n",
        "results_df_final_log = results_df_final.copy()\n",
        "results_df_final_log[scale_columns] = np.log1p(results_df_final_log[scale_columns])\n",
        "\n",
        "# Step 2: Scale\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(results_df_final_log[scale_columns])\n",
        "\n",
        "# Step 3: Replace the original values with the scaled ones\n",
        "results_df_final[scale_columns] = scaled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "-N-I1FB8uTlk",
        "outputId": "50a078e4-c3c7-49d4-cfbe-5b96e27fb124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      vendorid     lpep_pickup_datetime    lpep_dropoff_datetime  \\\n",
              "0            1  2015-02-13T19:49:20.000  2015-02-13T19:53:49.000   \n",
              "1            2  2015-02-26T19:17:29.000  2015-02-26T19:22:41.000   \n",
              "2            2  2015-02-17T14:10:19.000  2015-02-17T14:20:44.000   \n",
              "3            2  2015-02-06T21:07:34.000  2015-02-06T21:13:26.000   \n",
              "4            1  2015-02-19T08:41:04.000  2015-02-19T08:49:17.000   \n",
              "...        ...                      ...                      ...   \n",
              "9995         1  2015-02-14T10:21:02.000  2015-02-14T10:27:27.000   \n",
              "9996         2  2015-02-12T22:02:31.000  2015-02-12T22:11:26.000   \n",
              "9997         1  2015-02-26T22:04:06.000  2015-02-26T22:12:26.000   \n",
              "9998         2  2015-02-25T21:32:05.000  2015-02-25T22:07:30.000   \n",
              "9999         2  2015-02-14T01:33:13.000  2015-02-14T01:45:17.000   \n",
              "\n",
              "     store_and_fwd_flag  ratecodeid  pickup_longitude  pickup_latitude  \\\n",
              "0                     N           1        -73.994896        40.684578   \n",
              "1                     N           1        -73.993149        40.692768   \n",
              "2                     N           1        -73.991631        40.685059   \n",
              "3                     N           1        -73.910004        40.775623   \n",
              "4                     N           1        -74.000633        40.682995   \n",
              "...                 ...         ...               ...              ...   \n",
              "9995                  N           1        -73.942337        40.754093   \n",
              "9996                  N           1        -73.886497        40.747299   \n",
              "9997                  N           1        -73.888702        40.747257   \n",
              "9998                  N           1        -73.933228        40.704975   \n",
              "9999                  N           1        -73.966133        40.683266   \n",
              "\n",
              "      dropoff_longitude  dropoff_latitude  passenger_count  trip_distance  \\\n",
              "0            -74.003479         40.680717         0.965753      -1.060010   \n",
              "1            -74.002129         40.684917        -0.389058      -0.841263   \n",
              "2            -73.996834         40.680424        -0.389058      -0.797171   \n",
              "3            -73.890762         40.768871        -0.389058      -0.523985   \n",
              "4            -73.989708         40.702469        -0.389058      -0.139310   \n",
              "...                 ...               ...              ...            ...   \n",
              "9995         -73.924614         40.756371        -0.389058      -0.538911   \n",
              "9996         -73.865860         40.736572        -0.389058      -0.367806   \n",
              "9997         -73.866844         40.750011        -0.389058      -0.465543   \n",
              "9998         -73.980232         40.672199         3.796894       1.262604   \n",
              "9999         -73.925911         40.691242         3.796894       0.312978   \n",
              "\n",
              "      fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
              "0       -1.027300    1.0      0.5   -0.701732           0.0   \n",
              "1       -1.027300    1.0      0.5    0.571171           0.0   \n",
              "2       -0.333401    0.0      0.5   -0.701732           0.0   \n",
              "3       -0.645420    0.5      0.5   -0.701732           0.0   \n",
              "4       -0.240873    0.0      0.5    0.850841           0.0   \n",
              "...           ...    ...      ...         ...           ...   \n",
              "9995    -0.645420    0.0      0.5    0.626653           0.0   \n",
              "9996    -0.333401    0.5      0.5    1.353347           0.0   \n",
              "9997    -0.431220    0.5      0.5   -0.701732           0.0   \n",
              "9998     1.546726    0.5      0.5   -0.701732           0.0   \n",
              "9999     0.228789    0.5      0.5   -0.701732           0.0   \n",
              "\n",
              "      improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
              "0                       0.3     -0.908004             2          1   \n",
              "1                       0.3     -0.624486             1          1   \n",
              "2                       0.3     -0.505350             2          1   \n",
              "3                       0.3     -0.695213             2          1   \n",
              "4                       0.3     -0.126179             1          1   \n",
              "...                     ...           ...           ...        ...   \n",
              "9995                    0.3     -0.514374             1          1   \n",
              "9996                    0.3      0.033350             1          1   \n",
              "9997                    0.3     -0.505350             2          1   \n",
              "9998                    0.3      1.365361             2          1   \n",
              "9999                    0.3      0.098451             2          1   \n",
              "\n",
              "     pickup_station_id  pickup_station_lat  pickup_station_lon  \\\n",
              "0          US1NYKN0025             40.6846            -73.9867   \n",
              "1          US1NYKN0025             40.6846            -73.9867   \n",
              "2          US1NYKN0025             40.6846            -73.9867   \n",
              "3          USW00014732             40.7794            -73.8803   \n",
              "4          US1NYKN0025             40.6846            -73.9867   \n",
              "...                ...                 ...                 ...   \n",
              "9995       USC00305804             40.7333            -73.9333   \n",
              "9996       US1NYQN0026             40.7544            -73.8882   \n",
              "9997       US1NYQN0026             40.7544            -73.8882   \n",
              "9998       USC00300958             40.6892            -73.9550   \n",
              "9999       USC00300958             40.6892            -73.9550   \n",
              "\n",
              "     dropoff_station_id  dropoff_station_lat  dropoff_station_lon pickup_date  \\\n",
              "0           US1NYKN0025              40.6846             -73.9867  2015-02-13   \n",
              "1           US1NYKN0025              40.6846             -73.9867  2015-02-26   \n",
              "2           US1NYKN0025              40.6846             -73.9867  2015-02-17   \n",
              "3           USW00014732              40.7794             -73.8803  2015-02-06   \n",
              "4           US1NYKN0025              40.6846             -73.9867  2015-02-19   \n",
              "...                 ...                  ...                  ...         ...   \n",
              "9995        USC00305804              40.7333             -73.9333  2015-02-14   \n",
              "9996        US1NYQN0026              40.7544             -73.8882  2015-02-12   \n",
              "9997        USC00302868              40.7667             -73.8667  2015-02-26   \n",
              "9998        US1NYKN0059              40.6597             -73.9828  2015-02-25   \n",
              "9999        USC00300958              40.6892             -73.9550  2015-02-14   \n",
              "\n",
              "     dropoff_date  pickup_PRCP  pickup_SNOW  pickup_SNWD  pickup_WESF  \\\n",
              "0      2015-02-13     0.709677    -0.134989     2.173632    -0.057541   \n",
              "1      2015-02-26    -0.150230    -0.134989     2.442349    -0.057541   \n",
              "2      2015-02-17     4.393393     8.218358     2.786509    17.379019   \n",
              "3      2015-02-06    -0.150230    -0.134989     2.539392    -0.057541   \n",
              "4      2015-02-19    -0.150230    -0.134989     2.716062    -0.057541   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995   2015-02-14    -0.150230    -0.134989    -0.407032    -0.057541   \n",
              "9996   2015-02-12    -0.150230    -0.134989    -0.407032    -0.057541   \n",
              "9997   2015-02-26    -0.150230    -0.134989    -0.407032    -0.057541   \n",
              "9998   2015-02-25    -0.150230    -0.134989    -0.407032    -0.057541   \n",
              "9999   2015-02-14    -0.150230    -0.134989    -0.407032    -0.057541   \n",
              "\n",
              "      pickup_WESD  pickup_DAPR  pickup_MDPR  pickup_ADPT  pickup_ASLP  \\\n",
              "0             0.0     2.397423     2.397423    -0.010001     2.397441   \n",
              "1             0.0     2.397423     2.397423    -0.010001     2.397441   \n",
              "2             0.0     2.397423     2.397423    -0.010001     2.397441   \n",
              "3             0.0     2.397423     2.397423    -0.010001     2.397441   \n",
              "4             0.0     2.397423     2.397423    -0.010001     2.397441   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995          0.0    -0.417114    -0.417114    -0.010001    -0.417114   \n",
              "9996          0.0    -0.417114    -0.417114    -0.010001    -0.417114   \n",
              "9997          0.0    -0.417114    -0.417114    -0.010001    -0.417114   \n",
              "9998          0.0    -0.417114    -0.417114    -0.010001    -0.417114   \n",
              "9999          0.0    -0.417114    -0.417114    -0.010001    -0.417114   \n",
              "\n",
              "      pickup_ASTP  pickup_AWBT  pickup_AWND  pickup_RHAV  pickup_RHMN  \\\n",
              "0        2.397456    -0.029056     2.438829     2.399235     2.397858   \n",
              "1        2.397456    -0.029056     2.438829     2.399235     2.397858   \n",
              "2        2.397456    -0.029056     2.438829     2.399235     2.397858   \n",
              "3        2.397456    -0.029056     2.752429     2.399235     2.397858   \n",
              "4        2.397456    -0.029056     2.438829     2.399235     2.397858   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995    -0.417114    -0.029056    -0.413629    -0.417083    -0.417076   \n",
              "9996    -0.417114    -0.029056    -0.413629    -0.417083    -0.417076   \n",
              "9997    -0.417114    -0.029056    -0.413629    -0.417083    -0.417076   \n",
              "9998    -0.417114    -0.029056    -0.413629    -0.417083    -0.417076   \n",
              "9999    -0.417114    -0.029056    -0.413629    -0.417083    -0.417076   \n",
              "\n",
              "      pickup_RHMX  pickup_TMAX  pickup_TMIN  pickup_WDF2  pickup_WDF5  \\\n",
              "0        2.401102     2.569046    -0.027917     2.434504     2.435545   \n",
              "1        2.401102     2.569046    -0.027917     2.434504     2.435545   \n",
              "2        2.401102     2.569046    -0.027917     2.434504     2.435545   \n",
              "3        2.401102    -0.375731    -0.027917     2.397182     2.380860   \n",
              "4        2.401102     2.569046    -0.027917     2.434504     2.435545   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995    -0.417080    -0.375731    -0.027917    -0.415604    -0.415921   \n",
              "9996    -0.417080    -0.375731    -0.027917    -0.415604    -0.415921   \n",
              "9997    -0.417080    -0.375731    -0.027917    -0.415604    -0.415921   \n",
              "9998    -0.417080    -0.375731    -0.027917    -0.415604    -0.415921   \n",
              "9999    -0.417080    -0.375731    -0.027917    -0.415604    -0.415921   \n",
              "\n",
              "      pickup_WSF2  pickup_WSF5  pickup_WT01  pickup_WT08  pickup_WT04  \\\n",
              "0        2.431984     2.403901     2.397423     2.397423     2.397423   \n",
              "1        2.431984     2.403901     2.397423     2.397423     2.397423   \n",
              "2        2.431984     2.403901     2.397423     2.397423     2.397423   \n",
              "3        2.532928     2.510825     2.397423     2.397423     2.397423   \n",
              "4        2.431984     2.403901     2.397423     2.397423     2.397423   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995    -0.416204    -0.416468    -0.417114    -0.417114    -0.417114   \n",
              "9996    -0.416204    -0.416468    -0.417114    -0.417114    -0.417114   \n",
              "9997    -0.416204    -0.416468    -0.417114    -0.417114    -0.417114   \n",
              "9998    -0.416204    -0.416468    -0.417114    -0.417114    -0.417114   \n",
              "9999    -0.416204    -0.416468    -0.417114    -0.417114    -0.417114   \n",
              "\n",
              "      pickup_WT02  pickup_WT06  pickup_TAVG  pickup_WT09  pickup_WT03  \\\n",
              "0        2.397423     2.397423     2.128072     2.397423     2.397423   \n",
              "1        2.397423     2.397423     2.128072     2.397423     2.397423   \n",
              "2        2.397423     2.397423     2.128072     2.397423     2.397423   \n",
              "3        2.397423     2.397423    -0.352089     2.397423     2.397423   \n",
              "4        2.397423     2.397423     2.128072     2.397423     2.397423   \n",
              "...           ...          ...          ...          ...          ...   \n",
              "9995    -0.417114    -0.417114    -0.352089    -0.417114    -0.417114   \n",
              "9996    -0.417114    -0.417114    -0.352089    -0.417114    -0.417114   \n",
              "9997    -0.417114    -0.417114    -0.352089    -0.417114    -0.417114   \n",
              "9998    -0.417114    -0.417114    -0.352089    -0.417114    -0.417114   \n",
              "9999    -0.417114    -0.417114    -0.352089    -0.417114    -0.417114   \n",
              "\n",
              "      dropoff_PRCP  dropoff_SNOW  dropoff_SNWD  dropoff_WESF  dropoff_WESD  \\\n",
              "0         0.567285     -0.170781      1.947323     -0.044969     -0.010001   \n",
              "1        -0.176234     -0.170781      2.195816     -0.044969     -0.010001   \n",
              "2         3.752409      6.755797      2.514075     18.733551     -0.010001   \n",
              "3        -0.176234     -0.170781      2.285556     -0.044969     -0.010001   \n",
              "4        -0.176234     -0.170781      2.448930     -0.044969     -0.010001   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995     -0.176234     -0.170781     -0.439116     -0.044969     -0.010001   \n",
              "9996     -0.176234     -0.170781     -0.439116     -0.044969     -0.010001   \n",
              "9997     -0.176234     -0.170781     -0.439116     -0.044969     -0.010001   \n",
              "9998     -0.176234     -0.170781     -0.439116     -0.044969     -0.010001   \n",
              "9999     -0.176234     -0.170781     -0.439116     -0.044969     -0.010001   \n",
              "\n",
              "      dropoff_DAPR  dropoff_MDPR  dropoff_ADPT  dropoff_ASLP  dropoff_ASTP  \\\n",
              "0         2.177748      2.176942     -0.017323       2.17730      2.177342   \n",
              "1         2.177748      2.176942     -0.017323       2.17730      2.177342   \n",
              "2         2.177748      2.176942     -0.017323       2.17730      2.177342   \n",
              "3         2.177748      2.176942     -0.017323       2.17730      2.177342   \n",
              "4         2.177748      2.176942     -0.017323       2.17730      2.177342   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995     -0.459266     -0.459283     -0.017323      -0.45929     -0.459290   \n",
              "9996     -0.459266     -0.459283     -0.017323      -0.45929     -0.459290   \n",
              "9997     -0.459266     -0.459283     -0.017323      -0.45929     -0.459290   \n",
              "9998     -0.459266     -0.459283     -0.017323      -0.45929     -0.459290   \n",
              "9999     -0.459266     -0.459283     -0.017323      -0.45929     -0.459290   \n",
              "\n",
              "      dropoff_AWBT  dropoff_AWND  dropoff_RHAV  dropoff_RHMN  dropoff_RHMX  \\\n",
              "0         -0.05087      2.311575      2.180210      2.179062      2.183394   \n",
              "1         -0.05087      2.311575      2.180210      2.179062      2.183394   \n",
              "2         -0.05087      2.311575      2.180210      2.179062      2.183394   \n",
              "3         -0.05087      2.615231      2.180210      2.179062      2.183394   \n",
              "4         -0.05087      2.311575      2.180210      2.179062      2.183394   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995      -0.05087     -0.450431     -0.459204     -0.459195     -0.459207   \n",
              "9996      -0.05087     -0.450431     -0.459204     -0.459195     -0.459207   \n",
              "9997      -0.05087     -0.450431     -0.459204     -0.459195     -0.459207   \n",
              "9998      -0.05087     -0.450431     -0.459204     -0.459195     -0.459207   \n",
              "9999      -0.05087     -0.450431     -0.459204     -0.459195     -0.459207   \n",
              "\n",
              "      dropoff_TMAX  dropoff_TMIN  dropoff_WDF2  dropoff_WDF5  dropoff_WSF2  \\\n",
              "0         2.479477     -0.047916      2.275094      2.265444      2.266365   \n",
              "1         2.479477     -0.047916      2.275094      2.265444      2.266365   \n",
              "2         2.479477     -0.047916      2.275094      2.265444      2.266365   \n",
              "3        -0.368887     -0.047916      2.239346      2.213249      2.362886   \n",
              "4         2.479477     -0.047916      2.275094      2.265444      2.266365   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995     -0.368887     -0.047916     -0.454810     -0.456165     -0.457036   \n",
              "9996     -0.368887     -0.047916     -0.454810     -0.456165     -0.457036   \n",
              "9997     -0.368887     -0.047916     -0.454810     -0.456165     -0.457036   \n",
              "9998     -0.368887     -0.047916     -0.454810     -0.456165     -0.457036   \n",
              "9999     -0.368887     -0.047916     -0.454810     -0.456165     -0.457036   \n",
              "\n",
              "      dropoff_WSF5  dropoff_WT01  dropoff_WT08  dropoff_WT04  dropoff_WT02  \\\n",
              "0         2.201435      2.177275      2.177275      2.177275      2.177275   \n",
              "1         2.201435      2.177275      2.177275      2.177275      2.177275   \n",
              "2         2.201435      2.177275      2.177275      2.177275      2.177275   \n",
              "3         2.302244      2.177275      2.177275      2.177275      2.177275   \n",
              "4         2.201435      2.177275      2.177275      2.177275      2.177275   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "9995     -0.457642     -0.459290     -0.459290     -0.459290     -0.459290   \n",
              "9996     -0.457642     -0.459290     -0.459290     -0.459290     -0.459290   \n",
              "9997     -0.457642     -0.459290     -0.459290     -0.459290     -0.459290   \n",
              "9998     -0.457642     -0.459290     -0.459290     -0.459290     -0.459290   \n",
              "9999     -0.457642     -0.459290     -0.459290     -0.459290     -0.459290   \n",
              "\n",
              "      dropoff_WT06  dropoff_TAVG  dropoff_WT09  dropoff_WT03  ors_distance_m  \n",
              "0         2.177275      1.627991      2.177275      2.177275       -0.732381  \n",
              "1         2.177275      1.627991      2.177275      2.177275       -0.410823  \n",
              "2         2.177275      1.627991      2.177275      2.177275       -0.873201  \n",
              "3         2.177275     -0.338474      2.177275      2.177275       -0.225368  \n",
              "4         2.177275      1.627991      2.177275      2.177275        0.119566  \n",
              "...            ...           ...           ...           ...             ...  \n",
              "9995     -0.459290     -0.338474     -0.459290     -0.459290       -0.261113  \n",
              "9996     -0.459290     -0.338474     -0.459290     -0.459290        0.032486  \n",
              "9997     -0.459290     -0.338474     -0.459290     -0.459290       -0.127079  \n",
              "9998     -0.459290     -0.338474     -0.459290     -0.459290        0.858151  \n",
              "9999     -0.459290     -0.338474     -0.459290     -0.459290        0.518065  \n",
              "\n",
              "[10000 rows x 87 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4730db95-5701-46c9-801e-b44c34c9e16c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vendorid</th>\n",
              "      <th>lpep_pickup_datetime</th>\n",
              "      <th>lpep_dropoff_datetime</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>ratecodeid</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>trip_distance</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>extra</th>\n",
              "      <th>mta_tax</th>\n",
              "      <th>tip_amount</th>\n",
              "      <th>tolls_amount</th>\n",
              "      <th>improvement_surcharge</th>\n",
              "      <th>total_amount</th>\n",
              "      <th>payment_type</th>\n",
              "      <th>trip_type</th>\n",
              "      <th>pickup_station_id</th>\n",
              "      <th>pickup_station_lat</th>\n",
              "      <th>pickup_station_lon</th>\n",
              "      <th>dropoff_station_id</th>\n",
              "      <th>dropoff_station_lat</th>\n",
              "      <th>dropoff_station_lon</th>\n",
              "      <th>pickup_date</th>\n",
              "      <th>dropoff_date</th>\n",
              "      <th>pickup_PRCP</th>\n",
              "      <th>pickup_SNOW</th>\n",
              "      <th>pickup_SNWD</th>\n",
              "      <th>pickup_WESF</th>\n",
              "      <th>pickup_WESD</th>\n",
              "      <th>pickup_DAPR</th>\n",
              "      <th>pickup_MDPR</th>\n",
              "      <th>pickup_ADPT</th>\n",
              "      <th>pickup_ASLP</th>\n",
              "      <th>pickup_ASTP</th>\n",
              "      <th>pickup_AWBT</th>\n",
              "      <th>pickup_AWND</th>\n",
              "      <th>pickup_RHAV</th>\n",
              "      <th>pickup_RHMN</th>\n",
              "      <th>pickup_RHMX</th>\n",
              "      <th>pickup_TMAX</th>\n",
              "      <th>pickup_TMIN</th>\n",
              "      <th>pickup_WDF2</th>\n",
              "      <th>pickup_WDF5</th>\n",
              "      <th>pickup_WSF2</th>\n",
              "      <th>pickup_WSF5</th>\n",
              "      <th>pickup_WT01</th>\n",
              "      <th>pickup_WT08</th>\n",
              "      <th>pickup_WT04</th>\n",
              "      <th>pickup_WT02</th>\n",
              "      <th>pickup_WT06</th>\n",
              "      <th>pickup_TAVG</th>\n",
              "      <th>pickup_WT09</th>\n",
              "      <th>pickup_WT03</th>\n",
              "      <th>dropoff_PRCP</th>\n",
              "      <th>dropoff_SNOW</th>\n",
              "      <th>dropoff_SNWD</th>\n",
              "      <th>dropoff_WESF</th>\n",
              "      <th>dropoff_WESD</th>\n",
              "      <th>dropoff_DAPR</th>\n",
              "      <th>dropoff_MDPR</th>\n",
              "      <th>dropoff_ADPT</th>\n",
              "      <th>dropoff_ASLP</th>\n",
              "      <th>dropoff_ASTP</th>\n",
              "      <th>dropoff_AWBT</th>\n",
              "      <th>dropoff_AWND</th>\n",
              "      <th>dropoff_RHAV</th>\n",
              "      <th>dropoff_RHMN</th>\n",
              "      <th>dropoff_RHMX</th>\n",
              "      <th>dropoff_TMAX</th>\n",
              "      <th>dropoff_TMIN</th>\n",
              "      <th>dropoff_WDF2</th>\n",
              "      <th>dropoff_WDF5</th>\n",
              "      <th>dropoff_WSF2</th>\n",
              "      <th>dropoff_WSF5</th>\n",
              "      <th>dropoff_WT01</th>\n",
              "      <th>dropoff_WT08</th>\n",
              "      <th>dropoff_WT04</th>\n",
              "      <th>dropoff_WT02</th>\n",
              "      <th>dropoff_WT06</th>\n",
              "      <th>dropoff_TAVG</th>\n",
              "      <th>dropoff_WT09</th>\n",
              "      <th>dropoff_WT03</th>\n",
              "      <th>ors_distance_m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-13T19:49:20.000</td>\n",
              "      <td>2015-02-13T19:53:49.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.994896</td>\n",
              "      <td>40.684578</td>\n",
              "      <td>-74.003479</td>\n",
              "      <td>40.680717</td>\n",
              "      <td>0.965753</td>\n",
              "      <td>-1.060010</td>\n",
              "      <td>-1.027300</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.701732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.908004</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-13</td>\n",
              "      <td>2015-02-13</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>2.173632</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.397441</td>\n",
              "      <td>2.397456</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>2.438829</td>\n",
              "      <td>2.399235</td>\n",
              "      <td>2.397858</td>\n",
              "      <td>2.401102</td>\n",
              "      <td>2.569046</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>2.434504</td>\n",
              "      <td>2.435545</td>\n",
              "      <td>2.431984</td>\n",
              "      <td>2.403901</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.128072</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>0.567285</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>1.947323</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.177748</td>\n",
              "      <td>2.176942</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>2.17730</td>\n",
              "      <td>2.177342</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>2.311575</td>\n",
              "      <td>2.180210</td>\n",
              "      <td>2.179062</td>\n",
              "      <td>2.183394</td>\n",
              "      <td>2.479477</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>2.275094</td>\n",
              "      <td>2.265444</td>\n",
              "      <td>2.266365</td>\n",
              "      <td>2.201435</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>1.627991</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>-0.732381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-26T19:17:29.000</td>\n",
              "      <td>2015-02-26T19:22:41.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.993149</td>\n",
              "      <td>40.692768</td>\n",
              "      <td>-74.002129</td>\n",
              "      <td>40.684917</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.841263</td>\n",
              "      <td>-1.027300</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.571171</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.624486</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>2.442349</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.397441</td>\n",
              "      <td>2.397456</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>2.438829</td>\n",
              "      <td>2.399235</td>\n",
              "      <td>2.397858</td>\n",
              "      <td>2.401102</td>\n",
              "      <td>2.569046</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>2.434504</td>\n",
              "      <td>2.435545</td>\n",
              "      <td>2.431984</td>\n",
              "      <td>2.403901</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.128072</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>2.195816</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.177748</td>\n",
              "      <td>2.176942</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>2.17730</td>\n",
              "      <td>2.177342</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>2.311575</td>\n",
              "      <td>2.180210</td>\n",
              "      <td>2.179062</td>\n",
              "      <td>2.183394</td>\n",
              "      <td>2.479477</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>2.275094</td>\n",
              "      <td>2.265444</td>\n",
              "      <td>2.266365</td>\n",
              "      <td>2.201435</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>1.627991</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>-0.410823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-17T14:10:19.000</td>\n",
              "      <td>2015-02-17T14:20:44.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.991631</td>\n",
              "      <td>40.685059</td>\n",
              "      <td>-73.996834</td>\n",
              "      <td>40.680424</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.797171</td>\n",
              "      <td>-0.333401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.701732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.505350</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-17</td>\n",
              "      <td>2015-02-17</td>\n",
              "      <td>4.393393</td>\n",
              "      <td>8.218358</td>\n",
              "      <td>2.786509</td>\n",
              "      <td>17.379019</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.397441</td>\n",
              "      <td>2.397456</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>2.438829</td>\n",
              "      <td>2.399235</td>\n",
              "      <td>2.397858</td>\n",
              "      <td>2.401102</td>\n",
              "      <td>2.569046</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>2.434504</td>\n",
              "      <td>2.435545</td>\n",
              "      <td>2.431984</td>\n",
              "      <td>2.403901</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.128072</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>3.752409</td>\n",
              "      <td>6.755797</td>\n",
              "      <td>2.514075</td>\n",
              "      <td>18.733551</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.177748</td>\n",
              "      <td>2.176942</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>2.17730</td>\n",
              "      <td>2.177342</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>2.311575</td>\n",
              "      <td>2.180210</td>\n",
              "      <td>2.179062</td>\n",
              "      <td>2.183394</td>\n",
              "      <td>2.479477</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>2.275094</td>\n",
              "      <td>2.265444</td>\n",
              "      <td>2.266365</td>\n",
              "      <td>2.201435</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>1.627991</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>-0.873201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-06T21:07:34.000</td>\n",
              "      <td>2015-02-06T21:13:26.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.910004</td>\n",
              "      <td>40.775623</td>\n",
              "      <td>-73.890762</td>\n",
              "      <td>40.768871</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.523985</td>\n",
              "      <td>-0.645420</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.701732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.695213</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>USW00014732</td>\n",
              "      <td>40.7794</td>\n",
              "      <td>-73.8803</td>\n",
              "      <td>USW00014732</td>\n",
              "      <td>40.7794</td>\n",
              "      <td>-73.8803</td>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>2015-02-06</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>2.539392</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.397441</td>\n",
              "      <td>2.397456</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>2.752429</td>\n",
              "      <td>2.399235</td>\n",
              "      <td>2.397858</td>\n",
              "      <td>2.401102</td>\n",
              "      <td>-0.375731</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>2.397182</td>\n",
              "      <td>2.380860</td>\n",
              "      <td>2.532928</td>\n",
              "      <td>2.510825</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.352089</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>2.285556</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.177748</td>\n",
              "      <td>2.176942</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>2.17730</td>\n",
              "      <td>2.177342</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>2.615231</td>\n",
              "      <td>2.180210</td>\n",
              "      <td>2.179062</td>\n",
              "      <td>2.183394</td>\n",
              "      <td>-0.368887</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>2.239346</td>\n",
              "      <td>2.213249</td>\n",
              "      <td>2.362886</td>\n",
              "      <td>2.302244</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>-0.338474</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>-0.225368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-19T08:41:04.000</td>\n",
              "      <td>2015-02-19T08:49:17.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.000633</td>\n",
              "      <td>40.682995</td>\n",
              "      <td>-73.989708</td>\n",
              "      <td>40.702469</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.139310</td>\n",
              "      <td>-0.240873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.850841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.126179</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>US1NYKN0025</td>\n",
              "      <td>40.6846</td>\n",
              "      <td>-73.9867</td>\n",
              "      <td>2015-02-19</td>\n",
              "      <td>2015-02-19</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>2.716062</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.397441</td>\n",
              "      <td>2.397456</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>2.438829</td>\n",
              "      <td>2.399235</td>\n",
              "      <td>2.397858</td>\n",
              "      <td>2.401102</td>\n",
              "      <td>2.569046</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>2.434504</td>\n",
              "      <td>2.435545</td>\n",
              "      <td>2.431984</td>\n",
              "      <td>2.403901</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.128072</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>2.397423</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>2.448930</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>2.177748</td>\n",
              "      <td>2.176942</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>2.17730</td>\n",
              "      <td>2.177342</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>2.311575</td>\n",
              "      <td>2.180210</td>\n",
              "      <td>2.179062</td>\n",
              "      <td>2.183394</td>\n",
              "      <td>2.479477</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>2.275094</td>\n",
              "      <td>2.265444</td>\n",
              "      <td>2.266365</td>\n",
              "      <td>2.201435</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>1.627991</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>2.177275</td>\n",
              "      <td>0.119566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-14T10:21:02.000</td>\n",
              "      <td>2015-02-14T10:27:27.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.942337</td>\n",
              "      <td>40.754093</td>\n",
              "      <td>-73.924614</td>\n",
              "      <td>40.756371</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.538911</td>\n",
              "      <td>-0.645420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.626653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.514374</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>USC00305804</td>\n",
              "      <td>40.7333</td>\n",
              "      <td>-73.9333</td>\n",
              "      <td>USC00305804</td>\n",
              "      <td>40.7333</td>\n",
              "      <td>-73.9333</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>-0.407032</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>-0.413629</td>\n",
              "      <td>-0.417083</td>\n",
              "      <td>-0.417076</td>\n",
              "      <td>-0.417080</td>\n",
              "      <td>-0.375731</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>-0.415604</td>\n",
              "      <td>-0.415921</td>\n",
              "      <td>-0.416204</td>\n",
              "      <td>-0.416468</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.352089</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>-0.439116</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.459266</td>\n",
              "      <td>-0.459283</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>-0.45929</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>-0.450431</td>\n",
              "      <td>-0.459204</td>\n",
              "      <td>-0.459195</td>\n",
              "      <td>-0.459207</td>\n",
              "      <td>-0.368887</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>-0.454810</td>\n",
              "      <td>-0.456165</td>\n",
              "      <td>-0.457036</td>\n",
              "      <td>-0.457642</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.338474</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.261113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-12T22:02:31.000</td>\n",
              "      <td>2015-02-12T22:11:26.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.886497</td>\n",
              "      <td>40.747299</td>\n",
              "      <td>-73.865860</td>\n",
              "      <td>40.736572</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.367806</td>\n",
              "      <td>-0.333401</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.353347</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.033350</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYQN0026</td>\n",
              "      <td>40.7544</td>\n",
              "      <td>-73.8882</td>\n",
              "      <td>US1NYQN0026</td>\n",
              "      <td>40.7544</td>\n",
              "      <td>-73.8882</td>\n",
              "      <td>2015-02-12</td>\n",
              "      <td>2015-02-12</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>-0.407032</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>-0.413629</td>\n",
              "      <td>-0.417083</td>\n",
              "      <td>-0.417076</td>\n",
              "      <td>-0.417080</td>\n",
              "      <td>-0.375731</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>-0.415604</td>\n",
              "      <td>-0.415921</td>\n",
              "      <td>-0.416204</td>\n",
              "      <td>-0.416468</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.352089</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>-0.439116</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.459266</td>\n",
              "      <td>-0.459283</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>-0.45929</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>-0.450431</td>\n",
              "      <td>-0.459204</td>\n",
              "      <td>-0.459195</td>\n",
              "      <td>-0.459207</td>\n",
              "      <td>-0.368887</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>-0.454810</td>\n",
              "      <td>-0.456165</td>\n",
              "      <td>-0.457036</td>\n",
              "      <td>-0.457642</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.338474</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>0.032486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-26T22:04:06.000</td>\n",
              "      <td>2015-02-26T22:12:26.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.888702</td>\n",
              "      <td>40.747257</td>\n",
              "      <td>-73.866844</td>\n",
              "      <td>40.750011</td>\n",
              "      <td>-0.389058</td>\n",
              "      <td>-0.465543</td>\n",
              "      <td>-0.431220</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.701732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.505350</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>US1NYQN0026</td>\n",
              "      <td>40.7544</td>\n",
              "      <td>-73.8882</td>\n",
              "      <td>USC00302868</td>\n",
              "      <td>40.7667</td>\n",
              "      <td>-73.8667</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>2015-02-26</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>-0.407032</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>-0.413629</td>\n",
              "      <td>-0.417083</td>\n",
              "      <td>-0.417076</td>\n",
              "      <td>-0.417080</td>\n",
              "      <td>-0.375731</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>-0.415604</td>\n",
              "      <td>-0.415921</td>\n",
              "      <td>-0.416204</td>\n",
              "      <td>-0.416468</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.352089</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>-0.439116</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.459266</td>\n",
              "      <td>-0.459283</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>-0.45929</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>-0.450431</td>\n",
              "      <td>-0.459204</td>\n",
              "      <td>-0.459195</td>\n",
              "      <td>-0.459207</td>\n",
              "      <td>-0.368887</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>-0.454810</td>\n",
              "      <td>-0.456165</td>\n",
              "      <td>-0.457036</td>\n",
              "      <td>-0.457642</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.338474</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.127079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-25T21:32:05.000</td>\n",
              "      <td>2015-02-25T22:07:30.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.933228</td>\n",
              "      <td>40.704975</td>\n",
              "      <td>-73.980232</td>\n",
              "      <td>40.672199</td>\n",
              "      <td>3.796894</td>\n",
              "      <td>1.262604</td>\n",
              "      <td>1.546726</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.701732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>1.365361</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>USC00300958</td>\n",
              "      <td>40.6892</td>\n",
              "      <td>-73.9550</td>\n",
              "      <td>US1NYKN0059</td>\n",
              "      <td>40.6597</td>\n",
              "      <td>-73.9828</td>\n",
              "      <td>2015-02-25</td>\n",
              "      <td>2015-02-25</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>-0.407032</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>-0.413629</td>\n",
              "      <td>-0.417083</td>\n",
              "      <td>-0.417076</td>\n",
              "      <td>-0.417080</td>\n",
              "      <td>-0.375731</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>-0.415604</td>\n",
              "      <td>-0.415921</td>\n",
              "      <td>-0.416204</td>\n",
              "      <td>-0.416468</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.352089</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>-0.439116</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.459266</td>\n",
              "      <td>-0.459283</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>-0.45929</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>-0.450431</td>\n",
              "      <td>-0.459204</td>\n",
              "      <td>-0.459195</td>\n",
              "      <td>-0.459207</td>\n",
              "      <td>-0.368887</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>-0.454810</td>\n",
              "      <td>-0.456165</td>\n",
              "      <td>-0.457036</td>\n",
              "      <td>-0.457642</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.338474</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>0.858151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>2</td>\n",
              "      <td>2015-02-14T01:33:13.000</td>\n",
              "      <td>2015-02-14T01:45:17.000</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.966133</td>\n",
              "      <td>40.683266</td>\n",
              "      <td>-73.925911</td>\n",
              "      <td>40.691242</td>\n",
              "      <td>3.796894</td>\n",
              "      <td>0.312978</td>\n",
              "      <td>0.228789</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.701732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.098451</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>USC00300958</td>\n",
              "      <td>40.6892</td>\n",
              "      <td>-73.9550</td>\n",
              "      <td>USC00300958</td>\n",
              "      <td>40.6892</td>\n",
              "      <td>-73.9550</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>2015-02-14</td>\n",
              "      <td>-0.150230</td>\n",
              "      <td>-0.134989</td>\n",
              "      <td>-0.407032</td>\n",
              "      <td>-0.057541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.029056</td>\n",
              "      <td>-0.413629</td>\n",
              "      <td>-0.417083</td>\n",
              "      <td>-0.417076</td>\n",
              "      <td>-0.417080</td>\n",
              "      <td>-0.375731</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>-0.415604</td>\n",
              "      <td>-0.415921</td>\n",
              "      <td>-0.416204</td>\n",
              "      <td>-0.416468</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.352089</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.417114</td>\n",
              "      <td>-0.176234</td>\n",
              "      <td>-0.170781</td>\n",
              "      <td>-0.439116</td>\n",
              "      <td>-0.044969</td>\n",
              "      <td>-0.010001</td>\n",
              "      <td>-0.459266</td>\n",
              "      <td>-0.459283</td>\n",
              "      <td>-0.017323</td>\n",
              "      <td>-0.45929</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.05087</td>\n",
              "      <td>-0.450431</td>\n",
              "      <td>-0.459204</td>\n",
              "      <td>-0.459195</td>\n",
              "      <td>-0.459207</td>\n",
              "      <td>-0.368887</td>\n",
              "      <td>-0.047916</td>\n",
              "      <td>-0.454810</td>\n",
              "      <td>-0.456165</td>\n",
              "      <td>-0.457036</td>\n",
              "      <td>-0.457642</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.338474</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>-0.459290</td>\n",
              "      <td>0.518065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 87 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4730db95-5701-46c9-801e-b44c34c9e16c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4730db95-5701-46c9-801e-b44c34c9e16c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4730db95-5701-46c9-801e-b44c34c9e16c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-13b315f9-d72e-427f-ad3a-25e2dbbf7f0a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13b315f9-d72e-427f-ad3a-25e2dbbf7f0a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-13b315f9-d72e-427f-ad3a-25e2dbbf7f0a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1f1130b2-f8eb-4348-a9f6-7ec37ef868be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_final')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f1130b2-f8eb-4348-a9f6-7ec37ef868be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_final');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_final"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "results_df_final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate the difference\n",
        "# results_df_final['duration_difference'] = results_df_final['trip_duration'] - results_df_final['ors_duration_s']\n",
        "\n",
        "# # Calculate Q1 and Q3 for the difference\n",
        "# Q1 = results_df_final['duration_difference'].quantile(0.25)\n",
        "# Q3 = results_df_final['duration_difference'].quantile(0.75)\n",
        "\n",
        "# # Calculate IQR\n",
        "# IQR = Q3 - Q1\n",
        "\n",
        "# # Define outlier bounds\n",
        "# lower_bound = Q1 - 1.5 * IQR\n",
        "# upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# # Identify outliers\n",
        "# outliers = results_df_final[\n",
        "#     (results_df_final['duration_difference'] < lower_bound) |\n",
        "#     (results_df_final['duration_difference'] > upper_bound)\n",
        "# ]\n",
        "\n",
        "# # Display the outliers\n",
        "# print(\"Outliers in duration difference:\")\n",
        "# print(outliers[['trip_duration', 'ors_duration_s', 'duration_difference']])"
      ],
      "metadata": {
        "id": "-roNiBYHDXWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWzvCBHC7J2_"
      },
      "outputs": [],
      "source": [
        "# # Make sure datetime columns are parsed correctly\n",
        "# results_df_final['lpep_pickup_datetime'] = pd.to_datetime(results_df_final['lpep_pickup_datetime'])\n",
        "# results_df_final['lpep_dropoff_datetime'] = pd.to_datetime(results_df_final['lpep_dropoff_datetime'])\n",
        "\n",
        "# # Calculate trip duration\n",
        "# results_df_final['trip_duration'] = (\n",
        "#     results_df_final['lpep_dropoff_datetime'] - results_df_final['lpep_pickup_datetime']\n",
        "# ).dt.total_seconds() / 60\n",
        "\n",
        "# # Define weather columns\n",
        "# weather_columns = [col for col in results_df_final.columns if col.startswith('pickup_') or col.startswith('dropoff_')]\n",
        "\n",
        "# features = []\n",
        "# targets = []\n",
        "\n",
        "# for i, row in results_df_final.iterrows():\n",
        "#     try:\n",
        "#         trip_distance = pd.to_numeric(row['trip_distance'], errors='coerce')\n",
        "#         passenger_count = pd.to_numeric(row['passenger_count'], errors='coerce')\n",
        "#         fare_amount = pd.to_numeric(row['fare_amount'], errors='coerce')\n",
        "#         tip_amount = pd.to_numeric(row['tip_amount'], errors='coerce')\n",
        "#         total_amount = pd.to_numeric(row['total_amount'], errors='coerce')\n",
        "#         ors_distance_m = pd.to_numeric(row['ors_distance_m'], errors='coerce')\n",
        "#         ors_duration_s = pd.to_numeric(row['ors_duration_s'], errors='coerce')\n",
        "\n",
        "#         base_features = [\n",
        "#             trip_distance,\n",
        "#             passenger_count,\n",
        "#             fare_amount,\n",
        "#             tip_amount,\n",
        "#             total_amount,\n",
        "#             ors_distance_m,\n",
        "#             ors_duration_s\n",
        "#         ]\n",
        "\n",
        "#         weather_features = [\n",
        "#             pd.to_numeric(row[col], errors='coerce') for col in weather_columns\n",
        "#         ]\n",
        "\n",
        "#         feature_vector = [0 if pd.isna(f) else f for f in base_features + weather_features]\n",
        "\n",
        "#         features.append(feature_vector)\n",
        "#         targets.append(row['trip_duration'])\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Skipping row {i} due to error: {e}\")\n",
        "#         # Optionally print the row causing the error for debugging\n",
        "#         # print(row)\n",
        "\n",
        "# # try:\n",
        "# #     # Convert to NumPy array\n",
        "# #     features_np = np.array(features, dtype=np.float32)\n",
        "\n",
        "# #     # ✅ Apply XGBoost for feature importance\n",
        "# #     from xgboost import XGBRegressor\n",
        "# #     xgb_model = XGBRegressor()\n",
        "# #     xgb_model.fit(features_np, results_df_final['trip_duration'])\n",
        "\n",
        "# #     importances = xgb_model.feature_importances_\n",
        "# #     top_n_idx = np.argsort(importances)[::-1][:15]  # Top 15 features\n",
        "\n",
        "# #     selected_features = features_np[:, top_n_idx]\n",
        "\n",
        "# #     # ✅ Apply PCA\n",
        "# #     from sklearn.decomposition import PCA\n",
        "# #     pca = PCA(n_components=0.95)  # Or fixed: n_components=32\n",
        "# #     features_pca = pca.fit_transform(selected_features)\n",
        "\n",
        "# #     # ✅ Convert to torch tensors\n",
        "# #     X = torch.tensor(features_pca, dtype=torch.float)\n",
        "# #     y = torch.tensor(targets, dtype=torch.float)\n",
        "\n",
        "# #     print(\"✅ Feature tensor shape:\", X.shape)\n",
        "# #     print(\"✅ Target tensor shape:\", y.shape)\n",
        "\n",
        "# # except ValueError as e:\n",
        "# #     print(f\"❌ Error converting features to numpy array: {e}\")\n",
        "# #     print(\"Please check the 'features' list for non-numeric values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R77i5qOYGXfM"
      },
      "outputs": [],
      "source": [
        "# # Ensure datetime columns are parsed correctly\n",
        "# results_df_final['lpep_pickup_datetime'] = pd.to_datetime(results_df_final['lpep_pickup_datetime'])\n",
        "# results_df_final['lpep_dropoff_datetime'] = pd.to_datetime(results_df_final['lpep_dropoff_datetime'])\n",
        "\n",
        "# # Calculate trip duration in minutes\n",
        "# results_df_final['trip_duration'] = (\n",
        "#     results_df_final['lpep_dropoff_datetime'] - results_df_final['lpep_pickup_datetime']\n",
        "# ).dt.total_seconds() / 60\n",
        "\n",
        "# # Extract weather-related columns\n",
        "# weather_columns = [col for col in results_df_final.columns if col.startswith('pickup_') or col.startswith('dropoff_')]\n",
        "\n",
        "# features = []\n",
        "# targets = []\n",
        "\n",
        "# # Feature construction\n",
        "# for i, row in results_df_final.iterrows():\n",
        "#     try:\n",
        "#         base_features = [\n",
        "#             pd.to_numeric(row['trip_distance'], errors='coerce'),\n",
        "#             pd.to_numeric(row['passenger_count'], errors='coerce'),\n",
        "#             pd.to_numeric(row['fare_amount'], errors='coerce'),\n",
        "#             pd.to_numeric(row['tip_amount'], errors='coerce'),\n",
        "#             pd.to_numeric(row['total_amount'], errors='coerce'),\n",
        "#             pd.to_numeric(row['ors_distance_m'], errors='coerce'),\n",
        "#             pd.to_numeric(row['ors_duration_s'], errors='coerce')\n",
        "#         ]\n",
        "\n",
        "#         weather_features = [pd.to_numeric(row[col], errors='coerce') for col in weather_columns]\n",
        "#         feature_vector = [0 if pd.isna(f) else f for f in base_features + weather_features]\n",
        "\n",
        "#         features.append(feature_vector)\n",
        "#         targets.append(row['trip_duration'])\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Skipping row {i} due to error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTkqtB1-lgGr"
      },
      "outputs": [],
      "source": [
        "# # Ensure datetime columns are parsed correctly\n",
        "# results_df_final['lpep_pickup_datetime'] = pd.to_datetime(results_df_final['lpep_pickup_datetime'])\n",
        "# results_df_final['lpep_dropoff_datetime'] = pd.to_datetime(results_df_final['lpep_dropoff_datetime'])\n",
        "\n",
        "# # Calculate trip duration in minutes\n",
        "# results_df_final['trip_duration'] = (\n",
        "#     results_df_final['lpep_dropoff_datetime'] - results_df_final['lpep_pickup_datetime']\n",
        "# ).dt.total_seconds() / 60\n",
        "\n",
        "# # Extract weather-related columns (already defined earlier, but redefined here)\n",
        "# # This is safe as it's just defining a list of column names.\n",
        "# # weather_columns = [col for col in results_df_final.columns if col.startswith('pickup_') or col.startswith('dropoff_')]\n",
        "\n",
        "# from xgboost import XGBRegressor\n",
        "# import numpy as np\n",
        "\n",
        "# # Define features and target\n",
        "# # Exclude the target variable 'trip_duration' and any identifier columns from features\n",
        "# features_columns = [col for col in results_df_final.columns if col not in ['trip_duration', 'lpep_pickup_datetime', 'lpep_dropoff_datetime']]\n",
        "\n",
        "# # --- Start of suggested changes ---\n",
        "\n",
        "# # Ensure all feature columns are numeric and handle missing/invalid values\n",
        "# for col in features_columns:\n",
        "#     # Convert column to numeric, coercing errors to NaN\n",
        "#     results_df_final[col] = pd.to_numeric(results_df_final[col], errors='coerce')\n",
        "\n",
        "# # Fill remaining NaNs with a suitable value (e.g., 0 or mean/median)\n",
        "# # Using 0 as in your previous scaling step for consistency, but consider alternatives if appropriate\n",
        "# results_df_final[features_columns] = results_df_final[features_columns].fillna(0)\n",
        "\n",
        "# # Optionally clip negative values if they don't make sense for certain features\n",
        "# results_df_final[features_columns] = results_df_final[features_columns].clip(lower=0)\n",
        "\n",
        "# # --- End of suggested changes ---\n",
        "\n",
        "\n",
        "# X = results_df_final[features_columns]\n",
        "# y = results_df_final['trip_duration']\n",
        "\n",
        "# # Ensure feature and target are in numpy format (XGBoost can also work with pandas DataFrames)\n",
        "# X_np = X.values\n",
        "# y_np = y.values\n",
        "\n",
        "# # Train XGBoost\n",
        "# xgb_model = XGBRegressor()\n",
        "# xgb_model.fit(X_np, y_np)\n",
        "\n",
        "# # Get feature importances\n",
        "# importances = xgb_model.feature_importances_\n",
        "\n",
        "# # Select top features (optional, based on your need)\n",
        "# # You can adjust top_k as needed\n",
        "# top_k = 60\n",
        "# top_indices = np.argsort(importances)[::-1][:top_k]\n",
        "\n",
        "# # Get the names of the top features\n",
        "# top_features_names = [features_columns[i] for i in top_indices]\n",
        "\n",
        "# print(\"Top Features (XGBoost):\", top_features_names)\n",
        "\n",
        "# # If you want to use only the top features for further processing:\n",
        "# X_selected_np = X_np[:, top_indices]\n",
        "\n",
        "# print(f\"Shape of selected features: {X_selected_np.shape}\")\n",
        "\n",
        "# # The following feature construction loop is no longer necessary for preparing data\n",
        "# # for the Autoencoder if you use X_selected_np directly. However, if you intend\n",
        "# # to use the 'features' and 'targets' lists for something else later, you might\n",
        "# # need to adjust this loop based on the cleaned DataFrame. Assuming you want to\n",
        "# # use the cleaned `X_selected_np` and `y_np` for the subsequent Autoencoder step:\n",
        "\n",
        "# # features = [] # No longer needed if using X_selected_np\n",
        "# targets = [] # No longer needed if using y_np\n",
        "\n",
        "# # # Feature construction (commented out as X_selected_np should be used instead)\n",
        "# for i, row in results_df_final.iterrows():\n",
        "#     try:\n",
        "# #         base_features = [\n",
        "# #             pd.to_numeric(row['trip_distance'], errors='coerce'),\n",
        "# #             pd.to_numeric(row['passenger_count'], errors='coerce'),\n",
        "# #             pd.to_numeric(row['fare_amount'], errors='coerce'),\n",
        "# #             pd.to_numeric(row['tip_amount'], errors='coerce'),\n",
        "# #             pd.to_numeric(row['total_amount'], errors='coerce'),\n",
        "# #             pd.to_numeric(row['ors_distance_m'], errors='coerce'),\n",
        "# #             pd.to_numeric(row['ors_duration_s'], errors='coerce')\n",
        "# #         ]\n",
        "\n",
        "# #         weather_features = [pd.to_numeric(row[col], errors='coerce') for col in weather_columns]\n",
        "# #         feature_vector = [0 if pd.isna(f) else f for f in base_features + weather_features]\n",
        "\n",
        "# #         features.append(feature_vector)\n",
        "#         targets.append(row['trip_duration'])\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Skipping row {i} due to error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure datetime columns are parsed correctly\n",
        "results_df_final['lpep_pickup_datetime'] = pd.to_datetime(results_df_final['lpep_pickup_datetime'])\n",
        "results_df_final['lpep_dropoff_datetime'] = pd.to_datetime(results_df_final['lpep_dropoff_datetime'])\n",
        "\n",
        "# Calculate trip duration in minutes\n",
        "results_df_final['trip_duration'] = (\n",
        "    results_df_final['lpep_dropoff_datetime'] - results_df_final['lpep_pickup_datetime']\n",
        ").dt.total_seconds() / 60\n",
        "\n",
        "results_df_final['log_trip_duration'] = np.log1p(results_df_final['trip_duration'])\n",
        "\n",
        "# Extract weather-related columns (already defined earlier, but redefined here)\n",
        "# This is safe as it's just defining a list of column names.\n",
        "# weather_columns = [col for col in results_df_final.columns if col.startswith('pickup_') or col.startswith('dropoff_')]\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "\n",
        "# Define features and target\n",
        "# Exclude the target variable 'trip_duration' and any identifier columns from features\n",
        "features_columns = [col for col in results_df_final.columns if col not in ['log_trip_duration','trip_duration', 'lpep_pickup_datetime', 'lpep_dropoff_datetime']]\n",
        "\n",
        "# Ensure all feature columns are numeric and handle missing/invalid values\n",
        "for col in features_columns:\n",
        "    # Convert column to numeric, coercing errors to NaN\n",
        "    results_df_final[col] = pd.to_numeric(results_df_final[col], errors='coerce')\n",
        "\n",
        "# Fill remaining NaNs with a suitable value (e.g., 0 or mean/median)\n",
        "# Using 0 as in your previous scaling step for consistency, but consider alternatives if appropriate\n",
        "results_df_final[features_columns] = results_df_final[features_columns].fillna(0)\n",
        "\n",
        "# Optionally clip negative values if they don't make sense for certain features\n",
        "results_df_final[features_columns] = results_df_final[features_columns].clip(lower=0)\n",
        "\n",
        "\n",
        "X = results_df_final[features_columns]\n",
        "y = results_df_final['log_trip_duration']\n",
        "\n",
        "# Ensure feature and target are in numpy format (XGBoost can also work with pandas DataFrames)\n",
        "X_np = X.values\n",
        "y_np = y.values\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_model = XGBRegressor()\n",
        "xgb_model.fit(X_np, y_np)\n",
        "\n",
        "# Get feature importances\n",
        "importances = xgb_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame of features and their importances\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': features_columns,\n",
        "    'importance': importances\n",
        "})\n",
        "\n",
        "# Sort by importance\n",
        "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Calculate cumulative importance\n",
        "feature_importance_df['cumulative_importance'] = feature_importance_df['importance'].cumsum()\n",
        "feature_importance_df['cumulative_percentage'] = feature_importance_df['cumulative_importance'] / feature_importance_df['importance'].sum()\n",
        "\n",
        "# Define a cumulative percentage threshold (e.g., 95%)\n",
        "cumulative_threshold = 0.95\n",
        "\n",
        "# Select features that reach the cumulative threshold\n",
        "selected_features_df = feature_importance_df[feature_importance_df['cumulative_percentage'] <= cumulative_threshold]\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_features_names = selected_features_df['feature'].tolist()\n",
        "\n",
        "print(f\"Top Features (XGBoost) covering {cumulative_threshold*100}% of total importance:\", selected_features_names)\n",
        "print(f\"Number of selected features: {len(selected_features_names)}\")\n",
        "\n",
        "# If you want to use only the selected features for further processing:\n",
        "X_selected_np = X[selected_features_names].values\n",
        "\n",
        "print(f\"Shape of selected features: {X_selected_np.shape}\")\n",
        "\n",
        "# The following feature construction loop is no longer necessary for preparing data\n",
        "# for the Autoencoder if you use X_selected_np directly. However, if you intend\n",
        "# to use the 'features' and 'targets' lists for something else later, you might\n",
        "# need to adjust this loop based on the cleaned DataFrame. Assuming you want to\n",
        "# use the cleaned `X_selected_np` and `y_np` for the subsequent Autoencoder step:\n",
        "\n",
        "# features = [] # No longer needed if using X_selected_np\n",
        "targets = [] # No longer needed if using y_np\n",
        "\n",
        "# # Feature construction (commented out as X_selected_np should be used instead)\n",
        "for i, row in results_df_final.iterrows():\n",
        "    try:\n",
        "#         base_features = [\n",
        "#             pd.to_numeric(row['trip_distance'], errors='coerce'),\n",
        "#             pd.to_numeric(row['passenger_count'], errors='coerce'),\n",
        "#             pd.to_numeric(row['fare_amount'], errors='coerce'),\n",
        "#             pd.to_numeric(row['tip_amount'], errors='coerce'),\n",
        "#             pd.to_numeric(row['total_amount'], errors='coerce'),\n",
        "#             pd.to_numeric(row['ors_distance_m'], errors='coerce'),\n",
        "#             pd.to_numeric(row['ors_duration_s'], errors='coerce')\n",
        "#         ]\n",
        "\n",
        "#         weather_features = [pd.to_numeric(row[col], errors='coerce') for col in weather_columns]\n",
        "#         feature_vector = [0 if pd.isna(f) else f for f in base_features + weather_features]\n",
        "\n",
        "#         features.append(feature_vector)\n",
        "        targets.append(row['trip_duration'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Skipping row {i} due to error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofvZRfAI3332",
        "outputId": "4f813c9d-8041-4eaf-f53a-a4e2c2b7ad71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Features (XGBoost) covering 95.0% of total importance: ['fare_amount', 'total_amount', 'trip_distance', 'mta_tax', 'ratecodeid', 'ors_distance_m', 'dropoff_RHAV', 'payment_type', 'tip_amount', 'dropoff_TAVG', 'trip_type', 'dropoff_ASLP', 'pickup_SNOW', 'dropoff_station_lat', 'pickup_station_lat', 'extra', 'pickup_PRCP', 'pickup_TMIN', 'dropoff_latitude', 'dropoff_SNOW', 'pickup_latitude', 'pickup_WSF2', 'improvement_surcharge', 'dropoff_WSF2', 'pickup_ASLP', 'pickup_AWND', 'dropoff_WDF5', 'pickup_WSF5']\n",
            "Number of selected features: 28\n",
            "Shape of selected features: (10000, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Define the Autoencoder class\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim=32):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, encoding_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded"
      ],
      "metadata": {
        "id": "kOSZxX6OrvjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iKiZE38G12Q"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# # Define the Autoencoder class\n",
        "# class Autoencoder(nn.Module):\n",
        "#     def __init__(self, input_dim, encoding_dim=32):\n",
        "#         super(Autoencoder, self).__init__()\n",
        "#         self.encoder = nn.Sequential(\n",
        "#             nn.Linear(input_dim, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(128, encoding_dim)\n",
        "#         )\n",
        "#         self.decoder = nn.Sequential(\n",
        "#             nn.Linear(encoding_dim, 128),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Linear(128, input_dim)\n",
        "#         )\n",
        "#         # self.encoder = nn.Sequential(\n",
        "#         #     nn.Linear(input_dim, 256),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(256, 128),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(128, 64),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(64, encoding_dim)\n",
        "#         # )\n",
        "\n",
        "#         # self.decoder = nn.Sequential(\n",
        "#         #     nn.Linear(encoding_dim, 64),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(64, 128),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(128, 256),\n",
        "#         #     nn.ReLU(),\n",
        "#         #     nn.Linear(256, input_dim)\n",
        "#         # )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         encoded = self.encoder(x)\n",
        "#         decoded = self.decoder(encoded)\n",
        "#         return encoded, decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDBD5YDIG6dB"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     features_np = np.array(features, dtype=np.float32)\n",
        "\n",
        "#     # Normalize features\n",
        "#     # from sklearn.preprocessing import StandardScaler\n",
        "#     # scaler = StandardScaler()\n",
        "#     # features_scaled = scaler.fit_transform(features_np)\n",
        "\n",
        "#     input_dim = features_np.shape[1]\n",
        "#     # pca = PCA(n_components=0.95)\n",
        "#     # pca.fit(features_scaled)\n",
        "#     # encoding_dim = pca.n_components_\n",
        "#     encoding_dim = 32  # Adjust as needed\n",
        "\n",
        "#     # Instantiate model and prepare for training\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     ae = Autoencoder(input_dim, encoding_dim).to(device)\n",
        "#     criterion = nn.MSELoss()\n",
        "#     optimizer = torch.optim.Adam(ae.parameters(), lr=1e-3)\n",
        "\n",
        "#     # Prepare data loader\n",
        "#     X_tensor = torch.tensor(features_np, dtype=torch.float32).to(device)\n",
        "#     dataset = TensorDataset(X_tensor)\n",
        "#     loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "#     # Training loop\n",
        "#     for epoch in range(50):\n",
        "#         ae.train()\n",
        "#         total_loss = 0\n",
        "#         for batch in loader:\n",
        "#             inputs = batch[0]\n",
        "#             optimizer.zero_grad()\n",
        "#             encoded, decoded = ae(inputs)\n",
        "#             loss = criterion(decoded, inputs)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss.item()\n",
        "#         print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "#     # Extract encoded features\n",
        "#     ae.eval()\n",
        "#     with torch.no_grad():\n",
        "#         features_encoded, _ = ae(X_tensor)\n",
        "\n",
        "#     X = features_encoded.cpu()\n",
        "#     y = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "#     print(\"✅ Encoded feature tensor shape (Autoencoder):\", X.shape)\n",
        "#     print(\"✅ Target tensor shape:\", y.shape)\n",
        "\n",
        "# except ValueError as e:\n",
        "#     print(f\"❌ Error converting features to numpy array: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    features_np = np.array(X_selected_np, dtype=np.float32)\n",
        "\n",
        "    # Normalize features\n",
        "    # from sklearn.preprocessing import StandardScaler\n",
        "    # scaler = StandardScaler()\n",
        "    # features_scaled = scaler.fit_transform(features_np)\n",
        "\n",
        "    input_dim = features_np.shape[1]\n",
        "    pca = PCA(n_components=0.95)\n",
        "    pca.fit(features_np)\n",
        "    encoding_dim = pca.n_components_\n",
        "    # encoding_dim = 32  # Adjust as needed\n",
        "\n",
        "    # Instantiate model and prepare for training\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    ae = Autoencoder(input_dim, encoding_dim).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(ae.parameters(), lr=1e-3)\n",
        "\n",
        "    # Prepare data loader\n",
        "    X_tensor = torch.tensor(features_np, dtype=torch.float32).to(device)\n",
        "    dataset = TensorDataset(X_tensor)\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(50):\n",
        "        ae.train()\n",
        "        total_loss = 0\n",
        "        for batch in loader:\n",
        "            inputs = batch[0]\n",
        "            optimizer.zero_grad()\n",
        "            encoded, decoded = ae(inputs)\n",
        "            loss = criterion(decoded, inputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "    # Extract encoded features\n",
        "    ae.eval()\n",
        "    with torch.no_grad():\n",
        "        features_encoded, _ = ae(X_tensor)\n",
        "\n",
        "    X = features_encoded.cpu()\n",
        "    y = torch.tensor(targets, dtype=torch.float32)\n",
        "\n",
        "    print(\"✅ Encoded feature tensor shape (Autoencoder):\", X.shape)\n",
        "    print(\"✅ Target tensor shape:\", y.shape)\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"❌ Error converting features to numpy array: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5ULmzB-sMAS",
        "outputId": "16670c6e-1eb4-4ac9-a3d6-0168b97d6247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4347.2766\n",
            "Epoch 2, Loss: 68.6046\n",
            "Epoch 3, Loss: 36.8563\n",
            "Epoch 4, Loss: 21.2468\n",
            "Epoch 5, Loss: 16.2330\n",
            "Epoch 6, Loss: 13.2463\n",
            "Epoch 7, Loss: 10.8556\n",
            "Epoch 8, Loss: 8.7895\n",
            "Epoch 9, Loss: 7.5423\n",
            "Epoch 10, Loss: 6.5663\n",
            "Epoch 11, Loss: 5.4587\n",
            "Epoch 12, Loss: 4.9426\n",
            "Epoch 13, Loss: 4.3728\n",
            "Epoch 14, Loss: 3.9948\n",
            "Epoch 15, Loss: 3.4962\n",
            "Epoch 16, Loss: 3.2334\n",
            "Epoch 17, Loss: 3.0395\n",
            "Epoch 18, Loss: 2.7645\n",
            "Epoch 19, Loss: 2.6590\n",
            "Epoch 20, Loss: 2.5179\n",
            "Epoch 21, Loss: 2.4993\n",
            "Epoch 22, Loss: 2.3674\n",
            "Epoch 23, Loss: 2.2958\n",
            "Epoch 24, Loss: 2.3415\n",
            "Epoch 25, Loss: 2.2743\n",
            "Epoch 26, Loss: 2.2103\n",
            "Epoch 27, Loss: 2.1734\n",
            "Epoch 28, Loss: 2.1505\n",
            "Epoch 29, Loss: 1.7744\n",
            "Epoch 30, Loss: 1.7081\n",
            "Epoch 31, Loss: 1.6526\n",
            "Epoch 32, Loss: 1.6022\n",
            "Epoch 33, Loss: 1.6709\n",
            "Epoch 34, Loss: 1.5955\n",
            "Epoch 35, Loss: 1.5416\n",
            "Epoch 36, Loss: 1.5641\n",
            "Epoch 37, Loss: 1.3018\n",
            "Epoch 38, Loss: 1.2505\n",
            "Epoch 39, Loss: 1.4360\n",
            "Epoch 40, Loss: 1.5357\n",
            "Epoch 41, Loss: 1.8521\n",
            "Epoch 42, Loss: 1.2028\n",
            "Epoch 43, Loss: 1.0820\n",
            "Epoch 44, Loss: 1.3228\n",
            "Epoch 45, Loss: 1.2039\n",
            "Epoch 46, Loss: 1.4550\n",
            "Epoch 47, Loss: 1.5522\n",
            "Epoch 48, Loss: 1.1736\n",
            "Epoch 49, Loss: 1.5413\n",
            "Epoch 50, Loss: 1.2434\n",
            "✅ Encoded feature tensor shape (Autoencoder): torch.Size([10000, 10])\n",
            "✅ Target tensor shape: torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LySSHxZ88x0t"
      },
      "outputs": [],
      "source": [
        "# # Ensure `X` is defined properly before edge construction\n",
        "# X_tensor = torch.tensor(np.array(features, dtype=np.float32), dtype=torch.float)\n",
        "\n",
        "# # Build k-NN graph edges (k=10)\n",
        "# k = 10\n",
        "# nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X_tensor)\n",
        "# distances, neighbors = nbrs.kneighbors(X_tensor)\n",
        "\n",
        "# edge_index_list = []\n",
        "# for i in range(X_tensor.shape[0]):\n",
        "#     for j in neighbors[i, 1:]:  # Skip self-edge\n",
        "#         edge_index_list.append([i, j])\n",
        "\n",
        "# # Convert to PyTorch tensor of shape `[2, num_edges]`\n",
        "# edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# # Create `edge_attr` (optional) if needed\n",
        "# edge_attr = torch.tensor(distances[:, 1:], dtype=torch.float).flatten()\n",
        "\n",
        "# print(f\"✅ Edge Index Shape: {edge_index.shape}\")  # Should be `[2, num_edges]`\n",
        "# print(f\"✅ Edge Attr Shape: {edge_attr.shape}\")  # Should match number of edges"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# # Use encoded features for k-NN\n",
        "# k = 10\n",
        "# nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X)  # X is from AE\n",
        "# distances, neighbors = nbrs.kneighbors(X)\n",
        "\n",
        "# # Edge construction\n",
        "# edge_index_list = []\n",
        "# for i in range(X.shape[0]):\n",
        "#     for j in neighbors[i, 1:]:  # skip self-loop\n",
        "#         edge_index_list.append([i, j])\n",
        "\n",
        "# edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# # Edge attributes (optional, flattened distance vector)\n",
        "# edge_attr = torch.tensor(distances[:, 1:], dtype=torch.float).flatten()\n",
        "\n",
        "# print(f\"✅ Edge Index Shape: {edge_index.shape}\")\n",
        "# print(f\"✅ Edge Attr Shape: {edge_attr.shape}\")"
      ],
      "metadata": {
        "id": "6WVQIWpElNwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# # Assume `X` is your node feature tensor [N, D]\n",
        "# X_np = X.numpy()\n",
        "# k = 10\n",
        "\n",
        "# # Build kNN graph\n",
        "# nbrs = NearestNeighbors(n_neighbors=k+1).fit(X_np)\n",
        "# distances, neighbors = nbrs.kneighbors(X_np)\n",
        "\n",
        "# # Build edge list\n",
        "# edge_index_list = []\n",
        "# edge_attr_list = []\n",
        "\n",
        "# for i in range(X_np.shape[0]):\n",
        "#     for j_idx in range(1, k + 1):  # skip self-loop\n",
        "#         j = neighbors[i, j_idx]\n",
        "\n",
        "#         xi = X[i]\n",
        "#         xj = X[j]\n",
        "\n",
        "#         # ---- Option 1: Euclidean Distance (scalar)\n",
        "#         dist = torch.norm(xi - xj).unsqueeze(0)\n",
        "\n",
        "#         # ---- Option 2: Absolute Feature Difference (vector)\n",
        "#         diff = torch.abs(xi - xj)\n",
        "\n",
        "#         # ---- Option 3: Cosine Similarity (scalar)\n",
        "#         cosine_sim = F.cosine_similarity(xi.unsqueeze(0), xj.unsqueeze(0)).unsqueeze(0)\n",
        "\n",
        "#         # ---- Option 4: Concatenate all\n",
        "#         edge_feat = torch.cat([dist, cosine_sim, diff], dim=0)\n",
        "\n",
        "#         edge_index_list.append([i, j])\n",
        "#         edge_attr_list.append(edge_feat)\n",
        "\n",
        "# # Convert to tensors\n",
        "# edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "# edge_attr = torch.stack(edge_attr_list)\n",
        "\n",
        "# print(f\"✅ edge_index shape: {edge_index.shape}\")  # [2, E]\n",
        "# print(f\"✅ edge_attr shape: {edge_attr.shape}\")    # [E, F]"
      ],
      "metadata": {
        "id": "YocmaZ5D2u3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "k = 10\n",
        "X_np = X.cpu().numpy()\n",
        "\n",
        "knn = NearestNeighbors(n_neighbors=k+1)\n",
        "knn.fit(X_np)\n",
        "distances, neighbors = knn.kneighbors(X_np)\n",
        "neighbors = torch.tensor(neighbors, dtype=torch.long)\n",
        "\n",
        "edge_index_list = []\n",
        "edge_attr_list = []\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "    for j_idx in range(1, k + 1):  # skip self-loop at j_idx=0\n",
        "        j = neighbors[i, j_idx]\n",
        "\n",
        "        xi = X[i]\n",
        "        xj = X[j]\n",
        "\n",
        "        xi_2d = xi.unsqueeze(0)\n",
        "        xj_2d = xj.unsqueeze(0)\n",
        "\n",
        "        dist = torch.norm(xi - xj).view(1)\n",
        "        diff = torch.abs(xi - xj)\n",
        "        cosine_sim = F.cosine_similarity(xi_2d, xj_2d).view(1)\n",
        "\n",
        "        edge_feat = torch.cat([dist, cosine_sim, diff], dim=0)\n",
        "\n",
        "        edge_index_list.append([i, j.item()])\n",
        "        edge_attr_list.append(edge_feat)\n",
        "\n",
        "edge_index_tensor = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "edge_attr_tensor = torch.stack(edge_attr_list)"
      ],
      "metadata": {
        "id": "qUBiV8v728aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"✅ edge_index shape: {edge_index_tensor.shape}\")  # [2, E]\n",
        "print(f\"✅ edge_attr shape: {edge_attr_tensor.shape}\")    # [E, F]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HWtxEA43Egx",
        "outputId": "9ce19dac-0afc-4ef8-c37f-6714811f9647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ edge_index shape: torch.Size([2, 100000])\n",
            "✅ edge_attr shape: torch.Size([100000, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLVvf7GugVwD"
      },
      "outputs": [],
      "source": [
        "# # X is already the encoded output from autoencoder\n",
        "# encoded_np = X.numpy()\n",
        "\n",
        "# # Make sure targets is in numpy format\n",
        "# targets_np = np.array(targets)\n",
        "\n",
        "# # Train XGBoost on encoded features\n",
        "# xgb_model = XGBRegressor()\n",
        "# xgb_model.fit(encoded_np, targets_np)\n",
        "\n",
        "# # Select top features\n",
        "# importances = xgb_model.feature_importances_\n",
        "# # top_k = 16\n",
        "# top_k = 10\n",
        "# top_indices = np.argsort(importances)[::-1][:top_k]\n",
        "# selected_encoded = encoded_np[:, top_indices]\n",
        "\n",
        "# # Convert to tensor for further use\n",
        "# X_tensor_selected = torch.tensor(selected_encoded, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc4GplSuIDa-"
      },
      "outputs": [],
      "source": [
        "# from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# # Ensure X_tensor is on CPU for sklearn\n",
        "# X_tensor = X.cpu()\n",
        "# X_np = X_tensor.numpy()  # Convert to NumPy for NearestNeighbors\n",
        "\n",
        "# # k-NN graph (skip self-loop)\n",
        "# k = 10\n",
        "# nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(X_np)\n",
        "# distances, neighbors = nbrs.kneighbors(X_np)\n",
        "\n",
        "# edge_index_list = []\n",
        "# edge_attr_list = []\n",
        "\n",
        "# for i in range(X_np.shape[0]):\n",
        "#     for idx, j in enumerate(neighbors[i, 1:]):  # skip self-edge (neighbors[i, 0])\n",
        "#         edge_index_list.append([i, j])\n",
        "#         edge_attr_list.append(distances[i, idx + 1])  # +1 to skip self-distance\n",
        "\n",
        "# # Convert to tensors\n",
        "# edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "# edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "# print(f\"✅ Edge Index Shape: {edge_index.shape}\")  # [2, num_edges]\n",
        "# print(f\"✅ Edge Attr Shape: {edge_attr.shape}\")    # [num_edges]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTBFC3Fw85MU",
        "outputId": "9539ec9d-1d93-405a-a58e-6e32fdce3a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data object created! Node shape: torch.Size([10000, 10]), Edge shape: torch.Size([2, 100000])\n"
          ]
        }
      ],
      "source": [
        "# Ensure `X`, `edge_index`, `edge_attr`, and labels `y` exist\n",
        "y_tensor = torch.tensor(targets, dtype=torch.float)\n",
        "y_tensor = torch.log1p(y_tensor)\n",
        "\n",
        "# Ensure edge attributes exist\n",
        "# edge_attr_tensor = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "# ✅ Create PyTorch Geometric Data object (fixes the issue)\n",
        "data = Data(\n",
        "    x=X,  # Node features\n",
        "    edge_index=edge_index_tensor,  # Connectivity between nodes\n",
        "    edge_attr=edge_attr_tensor,  # Edge attributes (distances)\n",
        "    y=y_tensor  # Target trip duration values\n",
        ")\n",
        "\n",
        "print(f\"✅ Data object created! Node shape: {data.x.shape}, Edge shape: {data.edge_index.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caD7SuX4hmpA",
        "outputId": "232a62c7-b345-4e87-ae78-1787f124c891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Test masks applied! Train nodes: 8000, Test nodes: 2000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Get total node count\n",
        "num_nodes = data.x.shape[0]\n",
        "\n",
        "# Generate indices and split into train/test (80/20)\n",
        "indices = np.arange(num_nodes)\n",
        "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define boolean masks for PyTorch Geometric\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[train_indices] = True\n",
        "test_mask[test_indices] = True\n",
        "\n",
        "# Assign masks to `Data` object\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "print(f\"✅ Train/Test masks applied! Train nodes: {train_mask.sum().item()}, Test nodes: {test_mask.sum().item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy5Eesbohr2H"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch import nn\n",
        "# from torch_geometric.nn import MessagePassing\n",
        "# from torch_geometric.data import Data\n",
        "\n",
        "# class GraphTransformerLayer(MessagePassing):\n",
        "#     def __init__(self, dim, heads=4, dropout=0.3):\n",
        "#         super().__init__(aggr='add')\n",
        "#         self.heads = heads\n",
        "#         self.dim = dim\n",
        "#         self.scale = (dim // heads) ** -0.5\n",
        "\n",
        "#         self.q_proj = nn.Linear(dim, dim)\n",
        "#         self.k_proj = nn.Linear(dim, dim)\n",
        "#         self.v_proj = nn.Linear(dim, dim)\n",
        "#         self.edge_proj = nn.Linear(1, dim)  # ✅ Edge embedding\n",
        "\n",
        "#         self.out_proj = nn.Linear(dim, dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.layernorm = nn.LayerNorm(dim)\n",
        "\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "#         residual = x\n",
        "#         x = self.layernorm(x)\n",
        "\n",
        "#         # ✅ Multi-Head Attention projections\n",
        "#         q = self.q_proj(x).view(x.size(0), self.heads, self.dim // self.heads)\n",
        "#         k = self.k_proj(x).view(x.size(0), self.heads, self.dim // self.heads)\n",
        "#         v = self.v_proj(x).view(x.size(0), self.heads, self.dim // self.heads)\n",
        "\n",
        "#         # ✅ Ensure edge embeddings align properly BEFORE propagation\n",
        "#         edge_emb = self.edge_proj(edge_attr).view(edge_attr.size(0), self.heads, self.dim // self.heads)\n",
        "\n",
        "#         # ✅ Debug Step to Confirm Matching Dimensions\n",
        "#         assert edge_emb.shape[-1] == q.shape[-1], f\"Shape mismatch: edge_emb {edge_emb.shape}, q {q.shape}\"\n",
        "\n",
        "#         out = self.propagate(edge_index, q=q, k=k, v=v, edge_emb=edge_emb)\n",
        "\n",
        "#         return self.out_proj(out.view(x.size(0), self.dim)) + residual  # ✅ Residual connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b5-TzWqhbC8"
      },
      "outputs": [],
      "source": [
        "# class GraphTransformerLayer(MessagePassing):\n",
        "#     def __init__(self, hidden_dim, heads=4, dropout=0.1):\n",
        "#         super().__init__(aggr='add')  # or 'mean'\n",
        "#         self.heads = heads\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.head_dim = hidden_dim // heads\n",
        "#         assert hidden_dim % heads == 0\n",
        "\n",
        "#         self.scale = self.head_dim ** -0.5\n",
        "\n",
        "#         self.q_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.k_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.v_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.edge_lin = nn.Linear(1, hidden_dim)  # edge_attr is 1D per edge\n",
        "\n",
        "#         self.out_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "#     def forward(self, x, edge_index, edge_attr):\n",
        "#         residual = x\n",
        "#         x = self.layer_norm(x)\n",
        "\n",
        "#         Q = self.q_lin(x)\n",
        "#         K = self.k_lin(x)\n",
        "#         V = self.v_lin(x)\n",
        "\n",
        "#         edge_emb = self.edge_lin(edge_attr.unsqueeze(-1))  # shape: [E, hidden_dim]\n",
        "\n",
        "#         out = self.propagate(edge_index, Q=Q, K=K, V=V, edge_emb=edge_emb, size=(x.size(0), x.size(0)))\n",
        "#         out = self.dropout(self.out_lin(out))\n",
        "\n",
        "#         return out + residual\n",
        "\n",
        "#     def message(self, Q_i, K_j, V_j, edge_emb, index):\n",
        "#         # Inside message — now safe to reshape\n",
        "#         Q_i = Q_i.view(-1, self.heads, self.head_dim)\n",
        "#         K_j = K_j.view(-1, self.heads, self.head_dim)\n",
        "#         V_j = V_j.view(-1, self.heads, self.head_dim)\n",
        "#         edge_emb = edge_emb.view(-1, self.heads, self.head_dim)\n",
        "\n",
        "#         attn_score = (Q_i * (K_j + edge_emb)).sum(dim=-1) * self.scale\n",
        "#         attn_score = softmax(attn_score, index)\n",
        "\n",
        "#         attn_score = self.dropout(attn_score)\n",
        "\n",
        "#         return V_j * attn_score.unsqueeze(-1)\n",
        "\n",
        "#     def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
        "#         out = scatter(inputs, index, dim=0, dim_size=dim_size, reduce='sum')\n",
        "#         return out.view(-1, self.hidden_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MennW-7YjZms"
      },
      "outputs": [],
      "source": [
        "# class GraphTransformerNet(nn.Module):\n",
        "#   def __init__(self, in_dim, hidden_dim=128, num_layers=2, heads=4):\n",
        "#     super().__init__()\n",
        "#     self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "#     self.layers = nn.ModuleList([\n",
        "#     GraphTransformerLayer(hidden_dim=hidden_dim, heads=heads) for _ in range(num_layers)\n",
        "#     ])\n",
        "#     self.norm = nn.LayerNorm(hidden_dim) # This line defines 'self.norm'\n",
        "#     self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "#   def forward(self, data):\n",
        "#     x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "#     x = self.input_proj(x)\n",
        "#     for layer in self.layers:\n",
        "#         x = layer(x, edge_index, edge_attr)\n",
        "#     x = self.norm(x)  # ✅ corrected this line\n",
        "#     return self.output_layer(x).squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphTransformerLayer(MessagePassing):\n",
        "    def __init__(self, hidden_dim, heads=4, dropout=0.1, edge_feature_dim=12): # Add edge_feature_dim\n",
        "        super().__init__(aggr='add')\n",
        "        self.heads = heads\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.head_dim = hidden_dim // heads\n",
        "        assert hidden_dim % heads == 0\n",
        "\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.q_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.k_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.v_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.edge_lin = nn.Linear(edge_feature_dim, hidden_dim)  # Change input dim\n",
        "\n",
        "        self.out_lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        residual = x\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        Q = self.q_lin(x)\n",
        "        K = self.k_lin(x)\n",
        "        V = self.v_lin(x)\n",
        "\n",
        "        # No unsqueeze(-1) needed here anymore as edge_attr is already [E, edge_feature_dim]\n",
        "        edge_emb = self.edge_lin(edge_attr)\n",
        "\n",
        "        out = self.propagate(edge_index, Q=Q, K=K, V=V, edge_emb=edge_emb, size=(x.size(0), x.size(0)))\n",
        "        out = self.dropout(self.out_lin(out))\n",
        "\n",
        "        return out + residual\n",
        "\n",
        "    def message(self, Q_i, K_j, V_j, edge_emb, index):\n",
        "        # Inside message — now safe to reshape\n",
        "        Q_i = Q_i.view(-1, self.heads, self.head_dim)\n",
        "        K_j = K_j.view(-1, self.heads, self.head_dim)\n",
        "        V_j = V_j.view(-1, self.heads, self.head_dim)\n",
        "        # edge_emb is already [batch_size, hidden_dim], reshape it\n",
        "        edge_emb = edge_emb.view(-1, self.heads, self.head_dim)\n",
        "\n",
        "        attn_score = (Q_i * (K_j + edge_emb)).sum(dim=-1) * self.scale\n",
        "        attn_score = softmax(attn_score, index)\n",
        "\n",
        "        attn_score = self.dropout(attn_score)\n",
        "\n",
        "        return V_j * attn_score.unsqueeze(-1)\n",
        "\n",
        "    def aggregate(self, inputs, index, ptr=None, dim_size=None):\n",
        "        out = scatter(inputs, index, dim=0, dim_size=dim_size, reduce='sum')\n",
        "        return out.view(-1, self.hidden_dim)"
      ],
      "metadata": {
        "id": "nu6k5p_3rTEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphTransformerNet(nn.Module):\n",
        "  def __init__(self, in_dim, hidden_dim=128, num_layers=2, heads=4, edge_feature_dim=12): # Add edge_feature_dim\n",
        "    super().__init__()\n",
        "    self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "    self.layers = nn.ModuleList([\n",
        "        GraphTransformerLayer(hidden_dim=hidden_dim, heads=heads, edge_feature_dim=edge_feature_dim) for _ in range(num_layers) # Pass edge_feature_dim\n",
        "    ])\n",
        "    self.norm = nn.LayerNorm(hidden_dim)\n",
        "    self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "  def forward(self, data):\n",
        "    x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "    x = self.input_proj(x)\n",
        "    for layer in self.layers:\n",
        "        x = layer(x, edge_index, edge_attr)\n",
        "    x = self.norm(x)\n",
        "    return self.output_layer(x).squeeze(-1)"
      ],
      "metadata": {
        "id": "hjVwfQgnrUYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gnmes9ajeN7"
      },
      "outputs": [],
      "source": [
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = GraphTransformerNet(in_dim=data.x.shape[1], hidden_dim=256, num_layers=4, heads=4).to(device)\n",
        "\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
        "# loss_fn = nn.MSELoss()\n",
        "\n",
        "# data = data.to(device)\n",
        "\n",
        "# for epoch in range(1,101):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     out = model(data)\n",
        "#     loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "#     loss.backward()\n",
        "#     torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # Eval\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         val_pred = model(data)\n",
        "#         val_loss = loss_fn(val_pred[data.test_mask], data.y[data.test_mask])\n",
        "\n",
        "#     print(f\"Epoch {epoch:03d} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the actual edge feature dimension\n",
        "actual_edge_feature_dim = edge_attr_tensor.shape[1]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GraphTransformerNet(in_dim=data.x.shape[1], hidden_dim=1024, num_layers=4, heads=4, edge_feature_dim=actual_edge_feature_dim).to(device) # Pass the actual dim\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "data = data.to(device)\n",
        "\n",
        "for epoch in range(1,101):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data)\n",
        "    # loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss = loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Eval\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_pred = model(data)\n",
        "        val_loss = loss_fn(val_pred[data.test_mask], data.y[data.test_mask])\n",
        "\n",
        "    print(f\"Epoch {epoch:03d} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZk_tqSPrdx_",
        "outputId": "726a9001-58fd-415d-a4d2-c2a4c3810cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Train Loss: 5.1089 | Val Loss: 2.2404\n",
            "Epoch 002 | Train Loss: 2.1870 | Val Loss: 0.7550\n",
            "Epoch 003 | Train Loss: 0.7124 | Val Loss: 0.7553\n",
            "Epoch 004 | Train Loss: 0.7263 | Val Loss: 1.0880\n",
            "Epoch 005 | Train Loss: 1.0586 | Val Loss: 1.0353\n",
            "Epoch 006 | Train Loss: 1.0092 | Val Loss: 0.7756\n",
            "Epoch 007 | Train Loss: 0.7449 | Val Loss: 0.5749\n",
            "Epoch 008 | Train Loss: 0.5389 | Val Loss: 0.6319\n",
            "Epoch 009 | Train Loss: 0.5917 | Val Loss: 0.7888\n",
            "Epoch 010 | Train Loss: 0.7450 | Val Loss: 0.8548\n",
            "Epoch 011 | Train Loss: 0.8079 | Val Loss: 0.8080\n",
            "Epoch 012 | Train Loss: 0.7654 | Val Loss: 0.6938\n",
            "Epoch 013 | Train Loss: 0.6520 | Val Loss: 0.5821\n",
            "Epoch 014 | Train Loss: 0.5428 | Val Loss: 0.5509\n",
            "Epoch 015 | Train Loss: 0.5139 | Val Loss: 0.5803\n",
            "Epoch 016 | Train Loss: 0.5456 | Val Loss: 0.5861\n",
            "Epoch 017 | Train Loss: 0.5508 | Val Loss: 0.5605\n",
            "Epoch 018 | Train Loss: 0.5256 | Val Loss: 0.5369\n",
            "Epoch 019 | Train Loss: 0.5011 | Val Loss: 0.5554\n",
            "Epoch 020 | Train Loss: 0.5176 | Val Loss: 0.5789\n",
            "Epoch 021 | Train Loss: 0.5375 | Val Loss: 0.5749\n",
            "Epoch 022 | Train Loss: 0.5346 | Val Loss: 0.5464\n",
            "Epoch 023 | Train Loss: 0.5080 | Val Loss: 0.5205\n",
            "Epoch 024 | Train Loss: 0.4849 | Val Loss: 0.5331\n",
            "Epoch 025 | Train Loss: 0.4974 | Val Loss: 0.5512\n",
            "Epoch 026 | Train Loss: 0.5191 | Val Loss: 0.5404\n",
            "Epoch 027 | Train Loss: 0.5064 | Val Loss: 0.5112\n",
            "Epoch 028 | Train Loss: 0.4755 | Val Loss: 0.5054\n",
            "Epoch 029 | Train Loss: 0.4684 | Val Loss: 0.5209\n",
            "Epoch 030 | Train Loss: 0.4822 | Val Loss: 0.5188\n",
            "Epoch 031 | Train Loss: 0.4809 | Val Loss: 0.4975\n",
            "Epoch 032 | Train Loss: 0.4589 | Val Loss: 0.4853\n",
            "Epoch 033 | Train Loss: 0.4506 | Val Loss: 0.4834\n",
            "Epoch 034 | Train Loss: 0.4482 | Val Loss: 0.4740\n",
            "Epoch 035 | Train Loss: 0.4378 | Val Loss: 0.4759\n",
            "Epoch 036 | Train Loss: 0.4387 | Val Loss: 0.4714\n",
            "Epoch 037 | Train Loss: 0.4336 | Val Loss: 0.4561\n",
            "Epoch 038 | Train Loss: 0.4197 | Val Loss: 0.4560\n",
            "Epoch 039 | Train Loss: 0.4222 | Val Loss: 0.4473\n",
            "Epoch 040 | Train Loss: 0.4124 | Val Loss: 0.4363\n",
            "Epoch 041 | Train Loss: 0.3989 | Val Loss: 0.4324\n",
            "Epoch 042 | Train Loss: 0.3942 | Val Loss: 0.4191\n",
            "Epoch 043 | Train Loss: 0.3825 | Val Loss: 0.4111\n",
            "Epoch 044 | Train Loss: 0.3735 | Val Loss: 0.4129\n",
            "Epoch 045 | Train Loss: 0.3736 | Val Loss: 0.4019\n",
            "Epoch 046 | Train Loss: 0.3623 | Val Loss: 0.3888\n",
            "Epoch 047 | Train Loss: 0.3532 | Val Loss: 0.3782\n",
            "Epoch 048 | Train Loss: 0.3436 | Val Loss: 0.4121\n",
            "Epoch 049 | Train Loss: 0.3699 | Val Loss: 0.4275\n",
            "Epoch 050 | Train Loss: 0.3842 | Val Loss: 0.3712\n",
            "Epoch 051 | Train Loss: 0.3322 | Val Loss: 0.3878\n",
            "Epoch 052 | Train Loss: 0.3569 | Val Loss: 0.4189\n",
            "Epoch 053 | Train Loss: 0.3907 | Val Loss: 0.3609\n",
            "Epoch 054 | Train Loss: 0.3292 | Val Loss: 0.3865\n",
            "Epoch 055 | Train Loss: 0.3444 | Val Loss: 0.4430\n",
            "Epoch 056 | Train Loss: 0.3964 | Val Loss: 0.3826\n",
            "Epoch 057 | Train Loss: 0.3409 | Val Loss: 0.3434\n",
            "Epoch 058 | Train Loss: 0.3100 | Val Loss: 0.3533\n",
            "Epoch 059 | Train Loss: 0.3215 | Val Loss: 0.3336\n",
            "Epoch 060 | Train Loss: 0.2971 | Val Loss: 0.3339\n",
            "Epoch 061 | Train Loss: 0.2971 | Val Loss: 0.3432\n",
            "Epoch 062 | Train Loss: 0.3129 | Val Loss: 0.3303\n",
            "Epoch 063 | Train Loss: 0.2964 | Val Loss: 0.3949\n",
            "Epoch 064 | Train Loss: 0.3520 | Val Loss: 0.4294\n",
            "Epoch 065 | Train Loss: 0.3840 | Val Loss: 0.3520\n",
            "Epoch 066 | Train Loss: 0.3137 | Val Loss: 0.3589\n",
            "Epoch 067 | Train Loss: 0.3317 | Val Loss: 0.4005\n",
            "Epoch 068 | Train Loss: 0.3754 | Val Loss: 0.3449\n",
            "Epoch 069 | Train Loss: 0.3158 | Val Loss: 0.3566\n",
            "Epoch 070 | Train Loss: 0.3160 | Val Loss: 0.3996\n",
            "Epoch 071 | Train Loss: 0.3569 | Val Loss: 0.3493\n",
            "Epoch 072 | Train Loss: 0.3110 | Val Loss: 0.3371\n",
            "Epoch 073 | Train Loss: 0.3075 | Val Loss: 0.3537\n",
            "Epoch 074 | Train Loss: 0.3264 | Val Loss: 0.3220\n",
            "Epoch 075 | Train Loss: 0.2902 | Val Loss: 0.4083\n",
            "Epoch 076 | Train Loss: 0.3655 | Val Loss: 0.4893\n",
            "Epoch 077 | Train Loss: 0.4424 | Val Loss: 0.4319\n",
            "Epoch 078 | Train Loss: 0.3876 | Val Loss: 0.3282\n",
            "Epoch 079 | Train Loss: 0.2921 | Val Loss: 0.3973\n",
            "Epoch 080 | Train Loss: 0.3731 | Val Loss: 0.5107\n",
            "Epoch 081 | Train Loss: 0.4898 | Val Loss: 0.4870\n",
            "Epoch 082 | Train Loss: 0.4666 | Val Loss: 0.3680\n",
            "Epoch 083 | Train Loss: 0.3416 | Val Loss: 0.3294\n",
            "Epoch 084 | Train Loss: 0.2942 | Val Loss: 0.3792\n",
            "Epoch 085 | Train Loss: 0.3384 | Val Loss: 0.3684\n",
            "Epoch 086 | Train Loss: 0.3285 | Val Loss: 0.3219\n",
            "Epoch 087 | Train Loss: 0.2879 | Val Loss: 0.3668\n",
            "Epoch 088 | Train Loss: 0.3406 | Val Loss: 0.4195\n",
            "Epoch 089 | Train Loss: 0.3952 | Val Loss: 0.3864\n",
            "Epoch 090 | Train Loss: 0.3618 | Val Loss: 0.3231\n",
            "Epoch 091 | Train Loss: 0.2911 | Val Loss: 0.3812\n",
            "Epoch 092 | Train Loss: 0.3398 | Val Loss: 0.4775\n",
            "Epoch 093 | Train Loss: 0.4323 | Val Loss: 0.4763\n",
            "Epoch 094 | Train Loss: 0.4306 | Val Loss: 0.3885\n",
            "Epoch 095 | Train Loss: 0.3473 | Val Loss: 0.3191\n",
            "Epoch 096 | Train Loss: 0.2855 | Val Loss: 0.3652\n",
            "Epoch 097 | Train Loss: 0.3385 | Val Loss: 0.4044\n",
            "Epoch 098 | Train Loss: 0.3798 | Val Loss: 0.3724\n",
            "Epoch 099 | Train Loss: 0.3462 | Val Loss: 0.3206\n",
            "Epoch 100 | Train Loss: 0.2886 | Val Loss: 0.3798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ0fuiBR8rZx",
        "outputId": "dfb6ff80-1ccf-4660-b603-0631c46e6892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MSE: 2517.7429, RMSE: 50.1771, MAE: 7.7514\n"
          ]
        }
      ],
      "source": [
        "# Put model in eval mode\n",
        "model.eval()\n",
        "\n",
        "# Predict on the whole data\n",
        "with torch.no_grad():\n",
        "    y_true_log = data.y[data.test_mask].cpu()\n",
        "    y_pred_log = model(data)[data.test_mask].cpu()\n",
        "\n",
        "    # Invert log1p transform for both true and predicted\n",
        "    y_true = torch.expm1(y_true_log).numpy()\n",
        "    y_pred = torch.expm1(y_pred_log).numpy()\n",
        "\n",
        "# Compute metrics on original scale\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "print(f\"✅ MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-WmbEStTRAz"
      },
      "outputs": [],
      "source": [
        "# ✅ MSE: 2792.8350, RMSE: 52.8473, MAE: 7.2910 LR=0.0005(XGBoost after AutoEncoder)\n",
        "# ✅ MSE: 2792.8350, RMSE: 52.8473, MAE: 7.2910 LR=0.001\n",
        "# ✅ MSE: 2792.8350, RMSE: 52.8473, MAE: 7.2910 LR=0.005\n",
        "# ✅ MSE: 2489.7803, RMSE: 49.8977, MAE: 10.2235 LR=0.005(without XGBoost)\n",
        "# ✅ MSE: 2496.4617, RMSE: 49.9646, MAE: 6.7214 LR=0.0005\n",
        "# ✅ MSE: 2488.2515, RMSE: 49.8824, MAE: 6.0232 LR=0.0001\n",
        "# ✅ MSE: 2473.4302, RMSE: 49.7336, MAE: 5.5335 LR=0.00005\n",
        "# ✅ MSE: 2474.0007, RMSE: 49.7393, MAE: 5.5127 LR=0.00005(200 Epochs)\n",
        "# ✅ MSE: 2466.4307, RMSE: 49.6632, MAE: 5.6064 LR=0.0001\n",
        "# ✅ MSE: 2463.9041, RMSE: 49.6377, MAE: 6.0469 LR=0.0005\n",
        "# ✅ MSE: 2552.4336, RMSE: 50.5216, MAE: 8.9440 LR=0.0075(XGBoost before AutoEncoder)\n",
        "# ✅ MSE: 2476.6125, RMSE: 49.7656, MAE: 6.4465 LR=0.0025\n",
        "# ✅ MSE: 2476.7358, RMSE: 49.7668, MAE: 6.7075 LR=0.0010\n",
        "# ✅ MSE: 4646.1660, RMSE: 68.1628, MAE: 37.3884 LR=0.01\n",
        "# 512\n",
        "# ✅ MSE: 2454.8347, RMSE: 49.5463, MAE: 8.2158 LR=0.005\n",
        "# ✅ MSE: 2466.7637, RMSE: 49.6665, MAE: 6.2676 LR=0.0005\n",
        "# ✅ MSE: 2470.3411, RMSE: 49.7025, MAE: 6.5692 LR=0.0001\n",
        "# 1024\n",
        "# ✅ MSE: 2527.8186, RMSE: 50.2774, MAE: 8.6457 LR=0.0001\n",
        "# REMOVED XGBOOST COMPLETELY\n",
        "# ✅ MSE: 2491.9697, RMSE: 49.9196, MAE: 6.4492 LR=0.0005(1024 layers)\n",
        "# ✅ MSE: 2466.4136, RMSE: 49.6630, MAE: 5.5489 LR=0.0001(512 layers)\n",
        "# ✅ MSE: 2499.7192, RMSE: 49.9972, MAE: 6.8488 LR=0.001(512 layers)\n",
        "# ✅ MSE: 2552.5129, RMSE: 50.5224, MAE: 9.1618 LR=0.005(512 layers)\n",
        "# NEW\n",
        "# ✅ MSE: 2460.8000, RMSE: 49.6065, MAE: 5.5718 LR=0.0005 (512 layers)\n",
        "# ✅ MSE: 2474.9258, RMSE: 49.7486, MAE: 5.6105 LR=0.0001 (512 layers)\n",
        "# ✅ MSE: 2485.1538, RMSE: 49.8513, MAE: 6.1427 LR=0.0001 (256 layers)\n",
        "# ✅ MSE: 2475.0776, RMSE: 49.7502, MAE: 5.7169 LR=0.0005 (256 layers)\n",
        "# ✅ MSE: 2470.5974, RMSE: 49.7051, MAE: 5.5847 LR=0.0001 (1024 layers)\n",
        "# ✅ MSE: 2488.0576, RMSE: 49.8804, MAE: 6.7893 LR=0.0001 (XGBOOST ADDED)(256,layers changed from 6 to 4)\n",
        "# ✅ MSE: 2461.3025, RMSE: 49.6115, MAE: 6.4547 lr=0.0005\n",
        "# ✅ MSE: 2481.7041, RMSE: 49.8167, MAE: 6.7667 lr=0.0005 (WITH NEW EDGE FEATURE)\n",
        "# ✅ MSE: 2481.8794, RMSE: 49.8185, MAE: 6.7684 lr=0.0001 (WITH NEW EDGE FEATURE)\n",
        "# ✅ MSE: 2460.1316, RMSE: 49.5997, MAE: 6.7087 lr=0.001 (WITH NEW EDGE FEATURE)\n",
        "# ✅ MSE: 2518.2893, RMSE: 50.1826, MAE: 10.3225 lr=0.01\n",
        "# ✅ MSE: 2528.0464, RMSE: 50.2797, MAE: 10.9376 lr=0.05\n",
        "# ✅ MSE: 2548.3523, RMSE: 50.4812, MAE: 9.2456\n",
        "# ✅ MSE: 2463.7146, RMSE: 49.6358, MAE: 6.4661 lr=0.005 (256 layers)\n",
        "# ✅ MSE: 2464.4778, RMSE: 49.6435, MAE: 7.2183 lr=0.005 (512 layers)\n",
        "# NEW WITH XGBOOST,PCA\n",
        "# ✅ MSE: 2468.9900, RMSE: 49.6889, MAE: 6.7444 lr=0.0001 (512 layers)\n",
        "# ✅ MSE: 2510.6665, RMSE: 50.1066, MAE: 7.8584 lr=0.0001 (256 layers)\n",
        "# ✅ MSE: 2449.1335, RMSE: 49.4887, MAE: 6.4916 lr=0.001 (100 epochs)\n",
        "# ✅ MSE: 2472.9341, RMSE: 49.7286, MAE: 6.4520 lr=0.001 (200 epochs)\n",
        "# ✅ MSE: 2488.9451, RMSE: 49.8893, MAE: 6.9611 lr=0.001 (300 epochs)\n",
        "# ✅ MSE: 2468.0688, RMSE: 49.6797, MAE: 6.5595 lr=0.001 (100 epochs, Y log transformed)\n",
        "# ✅ MSE: 2530.9546, RMSE: 50.3086, MAE: 8.4863 lr=0.0001 (100 epochs)\n",
        "# ✅ MSE: 2518.7507, RMSE: 50.1872, MAE: 7.1268 lr=0.0001 (512 layers)\n",
        "# ✅ MSE: 2559.8330, RMSE: 50.5948, MAE: 9.0850 lr=0.01 (256)\n",
        "# ✅ MSE: 2487.1152, RMSE: 49.8710, MAE: 7.0031 lr=0.005\n",
        "# ✅ MSE: 2507.3870, RMSE: 50.0738, MAE: 6.9342 lr=0.0005\n",
        "# ✅ MSE: 2544.2166, RMSE: 50.4402, MAE: 9.0655 lr=0.0075\n",
        "# ✅ MSE: 2544.1030, RMSE: 50.4391, MAE: 9.2660 lr=0.0125\n",
        "\n",
        "#NEW ARCHITECTURE\n",
        "# ✅ MSE: 2525.2334, RMSE: 50.2517, MAE: 8.2789 LR=0.0001(256)\n",
        "# ✅ MSE: 2481.8508, RMSE: 49.8182, MAE: 6.7564 LR=0.0001(1024)\n",
        "# ✅ MSE: 2517.7429, RMSE: 50.1771, MAE: 7.7514 LR=0.0001(num_layers=6)\n",
        "\n",
        "\n",
        "\n",
        "# 256 Layers\n",
        "# ✅ MSE: 2478.2808, RMSE: 49.7823, MAE: 5.8185 LR=0.001\n",
        "# ✅ MSE: 2485.5576, RMSE: 49.8554, MAE: 6.3461 LR=0.0001\n",
        "# ✅ MSE: 2475.6008, RMSE: 49.7554, MAE: 5.8108 LR=0.0005\n",
        "# ✅ MSE: 2482.3181, RMSE: 49.8229, MAE: 6.0710 LR=0.005\n",
        "# 128 Layers\n",
        "# ✅ MSE: 2538.7295, RMSE: 50.3858, MAE: 8.6981 LR=0.0001\n",
        "# ✅ MSE: 2460.4209, RMSE: 49.6026, MAE: 5.5671 LR=0.001\n",
        "# ✅ MSE: 2516.4053, RMSE: 50.1638, MAE: 7.6058 LR=0.005\n",
        "# ✅ MSE: 2487.6021, RMSE: 49.8759, MAE: 7.5315 LR=0.0005"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.histplot(results_df_final['trip_duration'], bins=100, kde=True)\n",
        "plt.xlim(0, 200)  # zoom in to see bulk distribution\n",
        "plt.title('Trip Duration Distribution')\n",
        "plt.xlabel('Duration (min)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "PYmEiQD3SsrY",
        "outputId": "4bc98320-9ceb-4296-a5e1-8ab22197e7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ATrM0hSNLofB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cic0o8pE_paB"
      },
      "outputs": [],
      "source": [
        "# print(f\"y: min={data.y.min().item():.2f}, max={data.y.max().item():.2f}, mean={data.y.mean().item():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "UoOfQn-m_1re",
        "outputId": "3c178b69-e6bd-4fef-aec9-0a88acf75b97"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = data.y[data.test_mask].cpu().numpy()\n",
        "y_pred = model(data).detach().cpu().numpy()[data.test_mask.cpu().numpy()]\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.scatter(y_true, y_pred, alpha=0.4)\n",
        "plt.xlabel(\"True y\")\n",
        "plt.ylabel(\"Predicted y\")\n",
        "plt.title(\"True vs Predicted y\")\n",
        "plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', label='Ideal')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "SGJUE7F7pWe5",
        "outputId": "b880bf88-cca8-4534-e5d6-32ff3ea5523f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Assuming your data object is already loaded and moved to device\n",
        "y = data.y.cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Raw target distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(y, bins=40, color='skyblue', edgecolor='black')\n",
        "plt.title('Raw Target (y) Distribution')\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Optionally, log1p-transformed target\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(np.log1p(y), bins=40, color='lightcoral', edgecolor='black')\n",
        "plt.title('log1p(y) Distribution')\n",
        "plt.xlabel('log1p(y)')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "cRP0TOVEpsLj",
        "outputId": "f820604f-634b-4a2a-baf1-8a678706b20c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'feature_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3329069859>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lightblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Feature {i} Distribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'feature_names' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x8000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = data.x.cpu().numpy()\n",
        "y = data.y.cpu().numpy()\n",
        "num_features = x.shape[1]\n",
        "\n",
        "# Plot all feature histograms\n",
        "plt.figure(figsize=(16, 2.5 * num_features))\n",
        "for i in range(num_features):\n",
        "    plt.subplot((num_features + 1) // 2, 2, i + 1)\n",
        "    plt.hist(x[:, i], bins=40, color='lightblue', edgecolor='black')\n",
        "    plt.title(f'Feature {i} Distribution')\n",
        "    plt.xlabel(feature_names[i])\n",
        "    plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlzvgO-zxnx3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3jixCeN7NAz"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.data import Data\n",
        "\n",
        "# # Ensure edge indices and attributes are also tensors\n",
        "# edge_index_tensor = torch.tensor(edge_index, dtype=torch.long)\n",
        "# edge_attr_tensor = torch.tensor(data.edge_attr, dtype=torch.float)\n",
        "\n",
        "# # Create PyTorch Geometric Data object\n",
        "# data = Data(x=X, edge_index=edge_index_tensor, edge_attr=edge_attr_tensor, y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8QmTXu77psU"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Get node indices\n",
        "# num_nodes = data.x.shape[0]\n",
        "# indices = np.arange(num_nodes)\n",
        "\n",
        "# # Split into train/test (80/20)\n",
        "# train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define masks for PyTorch Geometric\n",
        "# train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "# test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "# train_mask[train_indices] = True\n",
        "# test_mask[test_indices] = True\n",
        "\n",
        "# # Assign masks to graph data object\n",
        "# data.train_mask = train_mask\n",
        "# data.test_mask = test_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktdH1lrDihmP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0parI2P7A5o1jIoHjR+8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}