{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRgNmixM6SfxtP6x7a9oeY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darkcoder1995/Graph-Neural-Network/blob/main/Graphomer_Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJEzxZjAQT1g",
        "outputId": "d191b049-84b1-401a-cd50-a3260a09d4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1ji_BRQUam",
        "outputId": "b82f45b7-3069-406c-d7b0-bd54e015063c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt26cu124)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt26cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch_sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch_sparse) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sodapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90D4X3R40RfO",
        "outputId": "d1f70b1b-86a8-476e-944c-308741789f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sodapy in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: requests>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from sodapy) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.28.1->sodapy) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openrouteservice"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH0e5h_v0WRj",
        "outputId": "5838c989-85d8-40c8-c330-f42ce3496402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openrouteservice in /usr/local/lib/python3.11/dist-packages (2.3.3)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.11/dist-packages (from openrouteservice) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->openrouteservice) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.utils import degree, to_networkx\n",
        "from torch_geometric.data import Data, download_url # Import download_url from data\n",
        "import networkx as nx\n",
        "from typing import Tuple, Dict, List\n",
        "import zipfile # Import the zipfile module\n",
        "import os # Import os for path joining\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import MessagePassing\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import NeighborLoader"
      ],
      "metadata": {
        "id": "70xVa1PuTDUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\""
      ],
      "metadata": {
        "id": "fOOLM_3ZQgNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = 'ml-latest-small/movies.csv'\n",
        "rating_path = 'ml-latest-small/ratings.csv'\n",
        "# user_path = 'ml-latest-small/users.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU1Tzm7tQo6c",
        "outputId": "b7c2cf7f-b123-4601-f39d-a3a6ae946840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def floyd_warshall_gpu(adj_matrix):\n",
        "#     \"\"\"\n",
        "#     Computes all-pairs shortest paths using the Floyd-Warshall algorithm on GPU.\n",
        "#     adj_matrix: Tensor of shape (N, N) with 0 for self-loops and float('inf') for no direct edge.\n",
        "#     Returns:\n",
        "#         dist: Tensor of shape (N, N) with shortest path distances.\n",
        "#     \"\"\"\n",
        "#     N = adj_matrix.size(0)\n",
        "#     dist = adj_matrix.clone().to(torch.float32).to('cuda')\n",
        "#     for k in range(N):\n",
        "#         dist = torch.min(dist, dist[:, k].unsqueeze(1) + dist[k, :].unsqueeze(0))\n",
        "#     return dist"
      ],
      "metadata": {
        "id": "AL2M4U-aqHsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class CentralityEncoding(nn.Module):\n",
        "#     def __init__(self, max_in_degree, max_out_degree, node_dim):\n",
        "#         super().__init__()\n",
        "#         self.z_in = nn.Parameter(torch.randn(max_in_degree, node_dim))\n",
        "#         self.z_out = nn.Parameter(torch.randn(max_out_degree, node_dim))\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         num_nodes = x.size(0)\n",
        "#         in_deg = torch.bincount(edge_index[1], minlength=num_nodes).clamp(max=self.z_in.size(0) - 1)\n",
        "#         out_deg = torch.bincount(edge_index[0], minlength=num_nodes).clamp(max=self.z_out.size(0) - 1)\n",
        "#         return x + self.z_in[in_deg] + self.z_out[out_deg]\n",
        "\n",
        "# class SpatialEncoding(nn.Module):\n",
        "#     def __init__(self, max_dist):\n",
        "#         super().__init__()\n",
        "#         self.b = nn.Parameter(torch.randn(max_dist))\n",
        "\n",
        "#     def forward(self, x, dist_matrix):\n",
        "#         dist_matrix = dist_matrix.clamp(max=self.b.size(0) - 1).long()\n",
        "#         return self.b[dist_matrix]\n",
        "\n",
        "# class GraphormerAttentionHead(nn.Module):\n",
        "#     def __init__(self, dim_in, dim_qk, dim_v):\n",
        "#         super().__init__()\n",
        "#         self.q = nn.Linear(dim_in, dim_qk)\n",
        "#         self.k = nn.Linear(dim_in, dim_qk)\n",
        "#         self.v = nn.Linear(dim_in, dim_v)\n",
        "\n",
        "#     def forward(self, x, bias):\n",
        "#         q = self.q(x)\n",
        "#         k = self.k(x)\n",
        "#         v = self.v(x)\n",
        "#         attn_scores = (q @ k.transpose(0, 1)) / q.size(-1) ** 0.5\n",
        "#         attn_scores = attn_scores + bias\n",
        "#         attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "#         return attn_weights @ v\n",
        "\n",
        "# class GraphormerRecommender(nn.Module):\n",
        "#     def __init__(self, node_dim, max_in_degree, max_out_degree, max_path_distance):\n",
        "#         super().__init__()\n",
        "#         self.centrality = CentralityEncoding(max_in_degree, max_out_degree, node_dim)\n",
        "#         self.spatial = SpatialEncoding(max_path_distance)\n",
        "#         self.attn = GraphormerAttentionHead(node_dim, node_dim, node_dim)\n",
        "#         self.out = nn.Linear(node_dim, 1)\n",
        "\n",
        "#     def forward(self, x, edge_index, dist_matrix):\n",
        "#         x = self.centrality(x, edge_index)\n",
        "#         bias = self.spatial(x, dist_matrix)\n",
        "#         x = self.attn(x, bias)\n",
        "#         return self.out(x).squeeze(-1)"
      ],
      "metadata": {
        "id": "8RO0PlZbIlsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings = pd.read_csv(rating_path)\n",
        "# movies = pd.read_csv(movie_path)"
      ],
      "metadata": {
        "id": "260EezIIqePC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_id_map = {uid: i for i, uid in enumerate(ratings['userId'].unique())}\n",
        "# movie_id_map = {mid: i + len(user_id_map) for i, mid in enumerate(ratings['movieId'].unique())}"
      ],
      "metadata": {
        "id": "aikWX6GvqrrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# movies"
      ],
      "metadata": {
        "id": "jy38J1cDrWZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_movielens_data(movie_path, rating_path, min_ratings_per_user=10):\n",
        "#     ratings = pd.read_csv(rating_path)\n",
        "#     movies = pd.read_csv(movie_path)\n",
        "\n",
        "#     # Filter to active users only\n",
        "#     user_counts = ratings['userId'].value_counts()\n",
        "#     active_users = user_counts[user_counts >= min_ratings_per_user].index\n",
        "#     ratings = ratings[ratings['userId'].isin(active_users)]\n",
        "\n",
        "#     user_id_map = {uid: i for i, uid in enumerate(ratings['userId'].unique())}\n",
        "#     movie_id_map = {mid: i + len(user_id_map) for i, mid in enumerate(ratings['movieId'].unique())}\n",
        "\n",
        "#     edge_index = []\n",
        "#     edge_attr = []\n",
        "#     for _, row in ratings.iterrows():\n",
        "#         u, m, r = row['userId'], row['movieId'], row['rating']\n",
        "#         uid = user_id_map[u]\n",
        "#         mid = movie_id_map[m]\n",
        "#         edge_index.append([uid, mid])\n",
        "#         edge_index.append([mid, uid])\n",
        "#         edge_attr.append([r])\n",
        "#         edge_attr.append([r])\n",
        "\n",
        "#     edge_index = torch.tensor(edge_index).t().contiguous()\n",
        "#     edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "#     num_nodes = len(user_id_map) + len(movie_id_map)\n",
        "#     x = torch.randn((num_nodes, 64))\n",
        "\n",
        "#     # Create adjacency matrix\n",
        "#     adj_matrix = torch.full((num_nodes, num_nodes), float('inf'))\n",
        "#     adj_matrix[torch.arange(num_nodes), torch.arange(num_nodes)] = 0\n",
        "#     for i in range(edge_index.size(1)):\n",
        "#         src = edge_index[0, i]\n",
        "#         dst = edge_index[1, i]\n",
        "#         adj_matrix[src, dst] = 1  # Assuming unweighted edges for shortest path\n",
        "\n",
        "#     # Compute shortest path distances\n",
        "#     dist_matrix = floyd_warshall_gpu(adj_matrix)\n",
        "\n",
        "#     data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "#     data.dist_matrix = dist_matrix\n",
        "#     data.user_id_map = user_id_map\n",
        "#     data.movie_id_map = movie_id_map\n",
        "#     return data"
      ],
      "metadata": {
        "id": "Y7N-6Dsc2ZX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, data, epochs=50, lr=1e-3, batch_size=64):\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     model = model.to(device)\n",
        "#     data = data.to(device)\n",
        "\n",
        "#     # Optimizer & Learning Rate Scheduler\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "#     # Use NeighborLoader for mini-batch training\n",
        "#     train_loader = NeighborLoader(\n",
        "#         data, num_neighbors=[10] * 2, batch_size=batch_size, input_nodes=data.train_mask\n",
        "#     )\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         total_loss = 0\n",
        "#         for batch in train_loader:\n",
        "#             batch = batch.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "\n",
        "#             # Forward pass (include edge attributes!)\n",
        "#             out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
        "#             preds = out[batch.edge_index[1]]\n",
        "#             targets = batch.edge_attr.squeeze()\n",
        "\n",
        "#             # Loss & Backpropagation\n",
        "#             loss = F.mse_loss(preds, targets)\n",
        "#             loss.backward()\n",
        "\n",
        "#             # Apply gradient clipping\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "\n",
        "#             optimizer.step()\n",
        "#             total_loss += loss.item() * batch.num_nodes\n",
        "\n",
        "#         total_loss /= len(train_loader.dataset)\n",
        "#         scheduler.step(total_loss)  # Adjust LR based on loss trend\n",
        "\n",
        "#         print(f\"Epoch {epoch + 1}/{epochs} | Loss: {total_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")"
      ],
      "metadata": {
        "id": "GcFOOjnSrzwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Paths to the MovieLens dataset\n",
        "# movie_path = 'ml-latest-small/movies.csv'\n",
        "# rating_path = 'ml-latest-small/ratings.csv'\n",
        "\n",
        "# # Load data\n",
        "# data = load_movielens_data(movie_path, rating_path)\n",
        "\n",
        "# # Create model\n",
        "# model = GraphormerRecommender(\n",
        "#     node_dim=64,\n",
        "#     max_in_degree=10,\n",
        "#     max_out_degree=10,\n",
        "#     max_path_distance=10\n",
        "# )\n",
        "\n",
        "# # Train model\n",
        "# train(model, data)"
      ],
      "metadata": {
        "id": "Im36nTkhJEP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Floyd-Warshall GPU ---\n",
        "# def floyd_warshall_gpu(adj_matrix):\n",
        "#     N = adj_matrix.size(0)\n",
        "#     dist = adj_matrix.clone().float().to('cuda')\n",
        "#     for k in range(N):\n",
        "#         dist = torch.min(dist, dist[:, k].unsqueeze(1) + dist[k, :].unsqueeze(0))\n",
        "#     return dist"
      ],
      "metadata": {
        "id": "uGm8zXvqu12y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Centrality Encoding ---\n",
        "# class CentralityEncoding(nn.Module):\n",
        "#     def __init__(self, max_in_deg, max_out_deg, node_dim):\n",
        "#         super().__init__()\n",
        "#         self.z_in = nn.Parameter(torch.randn(max_in_deg, node_dim))\n",
        "#         self.z_out = nn.Parameter(torch.randn(max_out_deg, node_dim))\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         num_nodes = x.size(0)\n",
        "#         in_deg = torch.bincount(edge_index[1], minlength=num_nodes).clamp(max=self.z_in.size(0) - 1)\n",
        "#         out_deg = torch.bincount(edge_index[0], minlength=num_nodes).clamp(max=self.z_out.size(0) - 1)\n",
        "#         return x + self.z_in[in_deg] + self.z_out[out_deg]"
      ],
      "metadata": {
        "id": "dVo6JZyQu6Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Spatial Encoding ---\n",
        "# class SpatialEncoding(nn.Module):\n",
        "#     def __init__(self, max_dist, node_dim):\n",
        "#         super().__init__()\n",
        "#         self.b = nn.Parameter(torch.randn(max_dist, node_dim))\n",
        "\n",
        "#     def forward(self, dist_matrix):\n",
        "#         dist_matrix = dist_matrix.clamp(max=self.b.size(0) - 1).long()\n",
        "#         return self.b[dist_matrix]"
      ],
      "metadata": {
        "id": "sKUmru3Cu9EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Attention ---\n",
        "# class GraphormerAttentionHead(nn.Module):\n",
        "#     def __init__(self, dim_in):\n",
        "#         super().__init__()\n",
        "#         self.q = nn.Linear(dim_in, dim_in)\n",
        "#         self.k = nn.Linear(dim_in, dim_in)\n",
        "#         self.v = nn.Linear(dim_in, dim_in)\n",
        "\n",
        "#     def forward(self, x, bias):\n",
        "#         q, k, v = self.q(x), self.k(x), self.v(x)\n",
        "#         attn = (q @ k.T) / (q.size(-1) ** 0.5)\n",
        "#         attn += bias.sum(dim=-1)  # [N, N]\n",
        "#         attn = F.softmax(attn, dim=-1)\n",
        "#         return attn @ v"
      ],
      "metadata": {
        "id": "FAQmvnnzvAC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Graphormer Model ---\n",
        "# class GraphormerRecommender(nn.Module):\n",
        "#     def __init__(self, node_dim, max_in_deg, max_out_deg, max_dist):\n",
        "#         super().__init__()\n",
        "#         self.centrality = CentralityEncoding(max_in_deg, max_out_deg, node_dim)\n",
        "#         self.spatial = SpatialEncoding(max_dist, node_dim)\n",
        "#         self.attn = GraphormerAttentionHead(node_dim)\n",
        "#         self.out = nn.Linear(node_dim, 1)\n",
        "\n",
        "#     def forward(self, x, edge_index, dist_matrix):\n",
        "#         x = self.centrality(x, edge_index)\n",
        "#         bias = self.spatial(dist_matrix)\n",
        "#         x = self.attn(x, bias)\n",
        "#         return self.out(x).squeeze(-1)"
      ],
      "metadata": {
        "id": "mypeHJ4NvDmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Load Data ---\n",
        "# def load_movielens(movie_path, rating_path, min_ratings=10):\n",
        "#     ratings = pd.read_csv(rating_path)\n",
        "#     movies = pd.read_csv(movie_path)\n",
        "#     users = ratings['userId'].value_counts()\n",
        "#     active_users = users[users >= min_ratings].index\n",
        "#     ratings = ratings[ratings['userId'].isin(active_users)]\n",
        "\n",
        "#     uid_map = {uid: i for i, uid in enumerate(ratings['userId'].unique())}\n",
        "#     mid_map = {mid: i + len(uid_map) for i, mid in enumerate(ratings['movieId'].unique())}\n",
        "\n",
        "#     edge_index, edge_attr = [], []\n",
        "#     for _, row in ratings.iterrows():\n",
        "#         uid = uid_map[row['userId']]\n",
        "#         mid = mid_map[row['movieId']]\n",
        "#         edge_index += [[uid, mid], [mid, uid]]\n",
        "#         edge_attr += [[row['rating']], [row['rating']]]\n",
        "\n",
        "#     edge_index = torch.tensor(edge_index).T.contiguous()\n",
        "#     edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "#     num_nodes = len(uid_map) + len(mid_map)\n",
        "#     x = torch.randn((num_nodes, 64))\n",
        "\n",
        "#     adj = torch.full((num_nodes, num_nodes), float('inf'))\n",
        "#     adj[torch.arange(num_nodes), torch.arange(num_nodes)] = 0\n",
        "#     for src, dst in edge_index.T:\n",
        "#         adj[src, dst] = 1\n",
        "\n",
        "#     dist_matrix = floyd_warshall_gpu(adj)\n",
        "#     data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "#     data.dist_matrix = dist_matrix\n",
        "#     return data"
      ],
      "metadata": {
        "id": "vShKdgvGvHMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Training ---\n",
        "# def train(model, data, epochs=10):\n",
        "#     model = model.to('cuda')\n",
        "#     data = data.to('cuda')\n",
        "#     opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "#     loss_fn = nn.MSELoss()\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         model.train()\n",
        "#         opt.zero_grad()\n",
        "#         out = model(data.x, data.edge_index, data.dist_matrix)\n",
        "#         pred = out[data.edge_index[0]]\n",
        "#         target = data.edge_attr.squeeze()\n",
        "#         loss = loss_fn(pred, target)\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "j84gBQBxvMA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # --- Run ---\n",
        "# movie_path = 'ml-latest-small/movies.csv'\n",
        "# rating_path = 'ml-latest-small/ratings.csv'\n",
        "\n",
        "# data = load_movielens(movie_path, rating_path)\n",
        "# model = GraphormerRecommender(node_dim=64, max_in_deg=10, max_out_deg=10, max_dist=10)\n",
        "# train(model, data, epochs=10)"
      ],
      "metadata": {
        "id": "s3Q8Z9jVvPYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Graphormer Components ---- #\n",
        "\n",
        "class CentralityEncoding(nn.Module):\n",
        "    def __init__(self, max_in_degree, max_out_degree, node_dim):\n",
        "        super().__init__()\n",
        "        self.z_in = nn.Parameter(torch.randn(max_in_degree, node_dim))\n",
        "        self.z_out = nn.Parameter(torch.randn(max_out_degree, node_dim))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        num_nodes = x.size(0)\n",
        "        in_deg = torch.bincount(edge_index[1], minlength=num_nodes).clamp(max=self.z_in.size(0) - 1)\n",
        "        out_deg = torch.bincount(edge_index[0], minlength=num_nodes).clamp(max=self.z_out.size(0) - 1)\n",
        "        return x + self.z_in[in_deg] + self.z_out[out_deg]"
      ],
      "metadata": {
        "id": "tR4Xy3wx2RLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpatialBias(nn.Module):\n",
        "    def __init__(self, max_hops, dim):\n",
        "        super().__init__()\n",
        "        self.bias = nn.Embedding(max_hops + 1, dim)\n",
        "\n",
        "    def forward(self, edge_index, num_nodes):\n",
        "        edge_hops = torch.ones(edge_index.size(1), dtype=torch.long, device=edge_index.device)\n",
        "        edge_hops = edge_hops.clamp(max=self.bias.num_embeddings - 1)\n",
        "        return self.bias(edge_hops)  # [E, dim]"
      ],
      "metadata": {
        "id": "HT8QCQDN2Yqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphormerLayer(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.q = nn.Linear(dim, dim)\n",
        "        self.k = nn.Linear(dim, dim)\n",
        "        self.v = nn.Linear(dim, dim)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, edge_index, spatial_bias):\n",
        "        q = self.q(x)\n",
        "        k = self.k(x)\n",
        "        v = self.v(x)\n",
        "        row, col = edge_index\n",
        "        alpha = (q[row] * k[col]).sum(dim=-1) / q.size(-1) ** 0.5\n",
        "        alpha = alpha + spatial_bias.sum(dim=-1)\n",
        "        alpha = torch.softmax(alpha, dim=0)\n",
        "        out = torch.zeros_like(x)\n",
        "        out.index_add_(0, row, alpha.unsqueeze(-1) * v[col])\n",
        "        return self.dropout(self.proj(out))"
      ],
      "metadata": {
        "id": "4covtvRm2YnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphTransformerNet(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_layers, max_hops=1):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "        self.centrality = CentralityEncoding(32, 32, hidden_dim)\n",
        "        self.spatial_bias = SpatialBias(max_hops, hidden_dim)\n",
        "        self.layers = nn.ModuleList([GraphormerLayer(hidden_dim) for _ in range(num_layers)])\n",
        "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.input_proj(x)\n",
        "        x = self.centrality(x, edge_index)\n",
        "        spatial_bias = self.spatial_bias(edge_index, x.size(0))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index, spatial_bias)\n",
        "        x = self.norm(x)\n",
        "        return self.output_layer(x).squeeze(-1)"
      ],
      "metadata": {
        "id": "JPk9VNYy2YkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Dataset Loader ---- #\n",
        "\n",
        "def load_movielens_data(movie_path, rating_path, min_ratings_per_user=10):\n",
        "    ratings = pd.read_csv(rating_path)\n",
        "    movies = pd.read_csv(movie_path)\n",
        "\n",
        "    user_counts = ratings['userId'].value_counts()\n",
        "    active_users = user_counts[user_counts >= min_ratings_per_user].index\n",
        "    ratings = ratings[ratings['userId'].isin(active_users)]\n",
        "\n",
        "    user_id_map = {uid: i for i, uid in enumerate(ratings['userId'].unique())}\n",
        "    movie_id_map = {mid: i + len(user_id_map) for i, mid in enumerate(ratings['movieId'].unique())}\n",
        "\n",
        "    edge_index = []\n",
        "    edge_attr = []\n",
        "    y = torch.zeros(len(user_id_map) + len(movie_id_map))\n",
        "\n",
        "    for _, row in ratings.iterrows():\n",
        "        uid = user_id_map[row['userId']]\n",
        "        mid = movie_id_map[row['movieId']]\n",
        "        rating = row['rating']\n",
        "        edge_index.append([uid, mid])\n",
        "        edge_index.append([mid, uid])\n",
        "        edge_attr.append([rating])\n",
        "        edge_attr.append([rating])\n",
        "        y[mid] = rating  # Supervision on item nodes (e.g., movies)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "    num_nodes = len(user_id_map) + len(movie_id_map)\n",
        "    x = torch.randn((num_nodes, 64))  # Random init for node features\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "    data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    movie_ids = list(movie_id_map.values())\n",
        "    split = int(0.8 * len(movie_ids))\n",
        "    train_ids = movie_ids[:split]\n",
        "    test_ids = movie_ids[split:]\n",
        "    data.train_mask[train_ids] = True\n",
        "    data.test_mask[test_ids] = True\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "LxnOb70g2Yhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Main Execution ---- #\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    movie_path = 'ml-latest-small/movies.csv'\n",
        "    rating_path = 'ml-latest-small/ratings.csv'\n",
        "\n",
        "    data = load_movielens_data(movie_path, rating_path)\n",
        "\n",
        "    train_loader = NeighborLoader(data, input_nodes=data.train_mask, num_neighbors=[10, 10], batch_size=64)\n",
        "    val_loader = NeighborLoader(data, input_nodes=data.test_mask, num_neighbors=[10, 10], batch_size=64)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = GraphTransformerNet(in_dim=data.x.size(1), hidden_dim=128, num_layers=3).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(1, 51):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(batch)\n",
        "            loss = loss_fn(pred[batch.train_mask], batch.y[batch.train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * batch.train_mask.sum().item()\n",
        "\n",
        "        print(f\"Epoch {epoch:03d}, Train Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xPqQr7y2YeR",
        "outputId": "c7c6fdfc-965f-4bcc-8b5b-f2a59d70422d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001, Train Loss: 189489.6700\n",
            "Epoch 002, Train Loss: 106224.2420\n",
            "Epoch 003, Train Loss: 105431.3456\n",
            "Epoch 004, Train Loss: 105477.7980\n",
            "Epoch 005, Train Loss: 105860.1963\n",
            "Epoch 006, Train Loss: 105184.0393\n",
            "Epoch 007, Train Loss: 106582.7647\n",
            "Epoch 008, Train Loss: 105877.6009\n",
            "Epoch 009, Train Loss: 105858.9067\n",
            "Epoch 010, Train Loss: 105602.5273\n",
            "Epoch 011, Train Loss: 104621.6932\n",
            "Epoch 012, Train Loss: 105142.2777\n",
            "Epoch 013, Train Loss: 105325.0419\n",
            "Epoch 014, Train Loss: 105198.4142\n",
            "Epoch 015, Train Loss: 104121.1250\n",
            "Epoch 016, Train Loss: 104699.6626\n",
            "Epoch 017, Train Loss: 104276.4174\n",
            "Epoch 018, Train Loss: 103794.4357\n",
            "Epoch 019, Train Loss: 103328.7948\n",
            "Epoch 020, Train Loss: 104387.4779\n",
            "Epoch 021, Train Loss: 103912.6172\n",
            "Epoch 022, Train Loss: 105020.6069\n",
            "Epoch 023, Train Loss: 104283.7223\n",
            "Epoch 024, Train Loss: 104444.5142\n",
            "Epoch 025, Train Loss: 104339.4304\n",
            "Epoch 026, Train Loss: 103493.9160\n",
            "Epoch 027, Train Loss: 104436.8517\n",
            "Epoch 028, Train Loss: 103381.8570\n",
            "Epoch 029, Train Loss: 104416.4908\n",
            "Epoch 030, Train Loss: 104329.9985\n",
            "Epoch 031, Train Loss: 104815.3519\n",
            "Epoch 032, Train Loss: 104213.1919\n",
            "Epoch 033, Train Loss: 103699.3716\n",
            "Epoch 034, Train Loss: 104126.4792\n",
            "Epoch 035, Train Loss: 103944.4149\n",
            "Epoch 036, Train Loss: 103673.2112\n",
            "Epoch 037, Train Loss: 104281.0046\n",
            "Epoch 038, Train Loss: 103297.6410\n",
            "Epoch 039, Train Loss: 103405.3997\n",
            "Epoch 040, Train Loss: 102845.0278\n",
            "Epoch 041, Train Loss: 103287.0222\n",
            "Epoch 042, Train Loss: 103934.1545\n",
            "Epoch 043, Train Loss: 103134.9134\n",
            "Epoch 044, Train Loss: 104412.9877\n",
            "Epoch 045, Train Loss: 103657.7315\n",
            "Epoch 046, Train Loss: 103305.0896\n",
            "Epoch 047, Train Loss: 103591.3623\n",
            "Epoch 048, Train Loss: 103423.9705\n",
            "Epoch 049, Train Loss: 103620.8888\n",
            "Epoch 050, Train Loss: 104897.1664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Evaluation on Test Data ----\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch)\n",
        "        preds = out[batch.test_mask].cpu().numpy()\n",
        "        targets = batch.y[batch.test_mask].cpu().numpy()\n",
        "\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(targets)\n",
        "\n",
        "# Compute metrics\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = math.sqrt(mse)\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "print(f\"\\nðŸ“Š Test MSE: {mse:.4f}\")\n",
        "print(f\"ðŸ“‰ Test RMSE: {rmse:.4f}\")\n",
        "print(f\"ðŸŽ¯ Test MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "id": "T-Z9FnR728K_",
        "outputId": "7394026a-b6c7-4b56-bade-88e420ca0307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Test MSE: 1.3128\n",
            "ðŸ“‰ Test RMSE: 1.1458\n",
            "ðŸŽ¯ Test MAE: 0.8881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Š Test MSE: 1.3128\n",
        "# ðŸ“‰ Test RMSE: 1.1458\n",
        "# ðŸŽ¯ Test MAE: 0.8881"
      ],
      "metadata": {
        "id": "sARIPTlv5J55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, data, epochs=30, lr=1e-3):\n",
        "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#     model = model.to(device)\n",
        "#     data = data.to(device)\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "#     model.train()\n",
        "\n",
        "#     user_ids = list(data.user_id_map.values())\n",
        "#     movie_ids = list(data.movie_id_map.values())\n",
        "#     user_mask = torch.tensor([i in user_ids for i in data.edge_index[0]], device=device)\n",
        "#     movie_mask = torch.tensor([i in movie_ids for i in data.edge_index[1]], device=device)\n",
        "#     mask = user_mask & movie_mask\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(data.x, data.edge_index, data.dist_matrix)\n",
        "#         preds = out[data.edge_index[1][mask]]\n",
        "#         targets = data.edge_attr.squeeze()[mask]\n",
        "#         loss = F.mse_loss(preds, targets)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         print(f\"Epoch {epoch + 1}/{epochs} | Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "avMnghkXJB4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KpjsH4iZJHo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # === utils.py ===\n",
        "# def floyd_warshall_source_to_all(G, source, cutoff=None):\n",
        "#     if source not in G:\n",
        "#         raise nx.NodeNotFound(f\"Source {source} not in G\")\n",
        "\n",
        "#     edges = {edge: i for i, edge in enumerate(G.edges())}\n",
        "#     level = 0\n",
        "#     nextlevel = {source: 1}\n",
        "#     node_paths = {source: [source]}\n",
        "#     edge_paths = {source: []}\n",
        "\n",
        "#     while nextlevel:\n",
        "#         thislevel = nextlevel\n",
        "#         nextlevel = {}\n",
        "#         for v in thislevel:\n",
        "#             for w in G[v]:\n",
        "#                 if w not in node_paths:\n",
        "#                     node_paths[w] = node_paths[v] + [w]\n",
        "#                     edge_paths[w] = edge_paths[v] + [edges.get((node_paths[w][-2], w), 0)]\n",
        "#                     nextlevel[w] = 1\n",
        "#         level += 1\n",
        "#         if cutoff is not None and level >= cutoff:\n",
        "#             break\n",
        "\n",
        "#     return node_paths, edge_paths\n",
        "\n",
        "# def all_pairs_shortest_path(G) -> Tuple[Dict[int, Dict[int, List[int]]], Dict[int, Dict[int, List[int]]]]:\n",
        "#     node_paths, edge_paths = {}, {}\n",
        "#     for node in G:\n",
        "#         n_path, e_path = floyd_warshall_source_to_all(G, node)\n",
        "#         node_paths[node] = n_path\n",
        "#         edge_paths[node] = e_path\n",
        "#     return node_paths, edge_paths\n",
        "\n",
        "# def shortest_path_distance(data: Data):\n",
        "#     G = to_networkx(data)\n",
        "#     return all_pairs_shortest_path(G)\n",
        "\n",
        "\n",
        "# # === layers.py ===\n",
        "# class CentralityEncoding(nn.Module):\n",
        "#     def __init__(self, max_in_degree, max_out_degree, node_dim):\n",
        "#         super().__init__()\n",
        "#         self.z_in = nn.Parameter(torch.randn(max_in_degree, node_dim))\n",
        "#         self.z_out = nn.Parameter(torch.randn(max_out_degree, node_dim))\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         num_nodes = x.size(0)\n",
        "#         in_deg = degree(edge_index[1], num_nodes=num_nodes).long().clamp(max=self.z_in.size(0) - 1)\n",
        "#         out_deg = degree(edge_index[0], num_nodes=num_nodes).long().clamp(max=self.z_out.size(0) - 1)\n",
        "#         return x + self.z_in[in_deg] + self.z_out[out_deg]\n",
        "\n",
        "# class SpatialEncoding(nn.Module):\n",
        "#     def __init__(self, max_dist):\n",
        "#         super().__init__()\n",
        "#         self.b = nn.Parameter(torch.randn(max_dist))\n",
        "\n",
        "#     def forward(self, x, paths):\n",
        "#         mat = torch.zeros((x.size(0), x.size(0)), device=x.device)\n",
        "#         for i in paths:\n",
        "#             for j in paths[i]:\n",
        "#                 d = min(len(paths[i][j]), len(self.b)) - 1\n",
        "#                 mat[i][j] = self.b[d]\n",
        "#         return mat\n",
        "\n",
        "# def dot_product(x1, x2):\n",
        "#     return (x1 * x2).sum(dim=1)\n",
        "\n",
        "# class EdgeEncoding(nn.Module):\n",
        "#     def __init__(self, edge_dim, max_dist):\n",
        "#         super().__init__()\n",
        "#         self.edge_vector = nn.Parameter(torch.randn(max_dist, edge_dim))\n",
        "\n",
        "#     def forward(self, x, edge_attr, edge_paths):\n",
        "#         size = x.size(0)\n",
        "#         cij = torch.zeros((size, size), device=x.device)\n",
        "#         for i in edge_paths:\n",
        "#             for j in edge_paths[i]:\n",
        "#                 path = edge_paths[i][j][:len(self.edge_vector)]\n",
        "#                 idx = torch.tensor(path, dtype=torch.long, device=x.device)\n",
        "#                 if len(idx) == 0:\n",
        "#                     continue\n",
        "#                 cij[i][j] = dot_product(self.edge_vector[:len(idx)], edge_attr[idx]).mean()\n",
        "#         return torch.nan_to_num(cij)\n",
        "\n",
        "# class GraphormerAttentionHead(nn.Module):\n",
        "#     def __init__(self, dim_in, dim_q, dim_k, edge_dim, max_dist):\n",
        "#         super().__init__()\n",
        "#         self.edge_enc = EdgeEncoding(edge_dim, max_dist)\n",
        "#         self.q = nn.Linear(dim_in, dim_q)\n",
        "#         self.k = nn.Linear(dim_in, dim_k)\n",
        "#         self.v = nn.Linear(dim_in, dim_k)\n",
        "\n",
        "#     def forward(self, x, edge_attr, b, edge_paths, ptr=None):\n",
        "#         device = x.device\n",
        "#         mask_inf = torch.full((x.size(0), x.size(0)), -1e6, device=device)\n",
        "#         mask_zero = torch.zeros_like(mask_inf)\n",
        "\n",
        "#         if ptr is None:\n",
        "#             mask_inf.fill_(1)\n",
        "#             mask_zero.fill_(1)\n",
        "#         else:\n",
        "#             for i in range(len(ptr) - 1):\n",
        "#                 mask_inf[ptr[i]:ptr[i+1], ptr[i]:ptr[i+1]] = 1\n",
        "#                 mask_zero[ptr[i]:ptr[i+1], ptr[i]:ptr[i+1]] = 1\n",
        "\n",
        "#         q, k, v = self.q(x), self.k(x), self.v(x)\n",
        "#         c = self.edge_enc(x, edge_attr, edge_paths)\n",
        "#         a = self.compute_a(q, k, ptr)\n",
        "#         a = (a + b + c) * mask_inf\n",
        "#         alpha = torch.softmax(a, dim=-1) * mask_zero\n",
        "#         return alpha @ v\n",
        "\n",
        "#     def compute_a(self, q, k, ptr=None):\n",
        "#         if ptr is None:\n",
        "#             return q @ k.t() / q.size(-1) ** 0.5\n",
        "#         a = torch.zeros(q.size(0), q.size(0), device=q.device)\n",
        "#         for i in range(len(ptr) - 1):\n",
        "#             a[ptr[i]:ptr[i+1], ptr[i]:ptr[i+1]] = (\n",
        "#                 q[ptr[i]:ptr[i+1]] @ k[ptr[i]:ptr[i+1]].t()\n",
        "#             ) / q.size(-1) ** 0.5\n",
        "#         return a\n",
        "\n",
        "\n",
        "# # === Model Integration ===\n",
        "# class GraphormerRecommender(nn.Module):\n",
        "#     def __init__(self, node_dim, edge_dim, max_in_degree, max_out_degree, max_path_distance):\n",
        "#         super().__init__()\n",
        "#         self.centrality = CentralityEncoding(max_in_degree, max_out_degree, node_dim)\n",
        "#         self.spatial = SpatialEncoding(max_path_distance)\n",
        "#         self.attn = GraphormerAttentionHead(node_dim, node_dim, node_dim, edge_dim, max_path_distance)\n",
        "#         self.out = nn.Linear(node_dim, 1)  # Predict rating or score\n",
        "\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index, edge_attr, ptr = data.x, data.edge_index, data.edge_attr, data.ptr\n",
        "#         edge_paths = data.edge_paths\n",
        "#         node_paths = data.node_paths\n",
        "\n",
        "#         x = self.centrality(x, edge_index)\n",
        "#         b = self.spatial(x, node_paths)\n",
        "#         x = self.attn(x, edge_attr, b, edge_paths, ptr)\n",
        "#         return self.out(x).squeeze(-1)  # Final output as score per node\n",
        "\n",
        "\n",
        "# # This architecture can now be trained with a dataset like MovieLens,\n",
        "# # where users and items are nodes, and interactions are edges with ratings.\n",
        "# # Ensure `data` passed to `forward` contains `x`, `edge_index`, `edge_attr`, `ptr`, `edge_paths`, `node_paths`.\n"
      ],
      "metadata": {
        "id": "OhouiaFiQWma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def approximate_shortest_path_distance(edge_index, num_nodes, max_hops=5):\n",
        "#     G = nx.Graph()\n",
        "#     G.add_edges_from(edge_index.t().tolist())\n",
        "\n",
        "#     # Limit to k-hop paths\n",
        "#     node_paths = torch.full((num_nodes, num_nodes), float('inf'))\n",
        "#     for node in range(num_nodes):\n",
        "#         sp = nx.single_source_shortest_path_length(G, node, cutoff=max_hops)\n",
        "#         for target, dist in sp.items():\n",
        "#             node_paths[node, target] = dist\n",
        "\n",
        "#     node_paths[node_paths == float('inf')] = max_hops + 1\n",
        "#     return node_paths"
      ],
      "metadata": {
        "id": "10nuVp-ts3oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def floyd_warshall_source_to_all(G, source, cutoff=None):\n",
        "#     if source not in G:\n",
        "#         raise nx.NodeNotFound(f\"Source {source} not in G\")\n",
        "\n",
        "#     edges = {edge: i for i, edge in enumerate(G.edges())}\n",
        "#     level = 0\n",
        "#     nextlevel = {source: 1}\n",
        "#     node_paths = {source: [source]}\n",
        "#     edge_paths = {source: []}\n",
        "\n",
        "#     while nextlevel:\n",
        "#         thislevel = nextlevel\n",
        "#         nextlevel = {}\n",
        "#         for v in thislevel:\n",
        "#             for w in G[v]:\n",
        "#                 if w not in node_paths:\n",
        "#                     node_paths[w] = node_paths[v] + [w]\n",
        "#                     edge_paths[w] = edge_paths[v] + [edges.get((node_paths[w][-2], w), 0)]\n",
        "#                     nextlevel[w] = 1\n",
        "#         level += 1\n",
        "#         if cutoff is not None and level >= cutoff:\n",
        "#             break\n",
        "\n",
        "#     return node_paths, edge_paths"
      ],
      "metadata": {
        "id": "GHsRhN7Wmeed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_movielens_data(movie_path, rating_path, min_ratings_per_user=10):\n",
        "#     ratings = pd.read_csv(rating_path)\n",
        "#     movies = pd.read_csv(movie_path)\n",
        "\n",
        "#     # Filter to active users only\n",
        "#     user_counts = ratings['userId'].value_counts()\n",
        "#     active_users = user_counts[user_counts >= min_ratings_per_user].index\n",
        "#     ratings = ratings[ratings['userId'].isin(active_users)]\n",
        "\n",
        "#     user_id_map = {uid: i for i, uid in enumerate(ratings['userId'].unique())}\n",
        "#     movie_id_map = {mid: i + len(user_id_map) for i, mid in enumerate(ratings['movieId'].unique())}\n",
        "\n",
        "#     edge_index, edge_attr, x = [], [], []\n",
        "#     for _, row in ratings.iterrows():\n",
        "#         u, m, r = row['userId'], row['movieId'], row['rating']\n",
        "#         uid = user_id_map[u]\n",
        "#         mid = movie_id_map[m]\n",
        "\n",
        "#         edge_index.append([uid, mid])\n",
        "#         edge_index.append([mid, uid])\n",
        "#         edge_attr.append([r])\n",
        "#         edge_attr.append([r])\n",
        "\n",
        "#     edge_index = torch.tensor(edge_index).t().contiguous()\n",
        "#     edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "\n",
        "#     num_nodes = len(user_id_map) + len(movie_id_map)\n",
        "#     x = torch.randn((num_nodes, 64))  # Node features\n",
        "\n",
        "#     data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "#     # Convert to networkx and compute shortest paths\n",
        "#     G = nx.Graph()\n",
        "#     G.add_edges_from(edge_index.t().tolist())\n",
        "#     node_paths, edge_paths = shortest_path_distance(data)\n",
        "\n",
        "#     data.node_paths = node_paths\n",
        "#     data.edge_paths = edge_paths\n",
        "#     data.ptr = torch.tensor([0, num_nodes])  # Single graph\n",
        "\n",
        "#     return data"
      ],
      "metadata": {
        "id": "hro0yOrocQO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, data, epochs=30, lr=1e-3):\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "#     model.train()\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         out = model(data)\n",
        "\n",
        "#         # Use only user -> movie edges for supervision\n",
        "#         mask = data.edge_index[0] < len(set(data.edge_index[0].tolist()))\n",
        "#         targets = data.edge_attr.squeeze()[mask]\n",
        "#         preds = out[data.edge_index[1][mask]]\n",
        "\n",
        "#         loss = F.mse_loss(preds, targets)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         print(f\"Epoch {epoch + 1}/{epochs} | Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "0XJxv1kqonna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Paths\n",
        "# movie_path = 'ml-latest-small/movies.csv'\n",
        "# rating_path = 'ml-latest-small/ratings.csv'\n",
        "\n",
        "# # Load data\n",
        "# data = load_movielens_data(movie_path, rating_path)\n",
        "\n",
        "# # Create model\n",
        "# model = GraphormerRecommender(\n",
        "#     node_dim=64,\n",
        "#     edge_dim=1,\n",
        "#     max_in_degree=10,\n",
        "#     max_out_degree=10,\n",
        "#     max_path_distance=10\n",
        "# )\n",
        "\n",
        "# # Train model\n",
        "# train(model, data)"
      ],
      "metadata": {
        "id": "ovjDa8JWqGqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}